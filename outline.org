# -*- compile-command: "./compile.sh" -*-
#+TITLE: A novel, multi-model, multi-task, method for computerized testing of emotional intelligence
#+AUTHOR: William Rudenmalm
#+EMAIL: me@whn.se
#+BIBLIOGRAPHY: refs plain
#+OPTIONS: num:4 toc:nil
#+LaTeX_HEADER: \input{preamble.tex}

\input{toc.tex}

* Introduction
  Emotions play a fundamental role in modulating the behavior and
  experiences of organisms. While the exact definition of the concept
  is debated, its importance is not \citep{Scherer2005}. The
  impact that emotions have on everyday life is enormous yet hard to
  pinpoint.

  \citet{Fontaine2007} define emotions as a set of interrelated
  components, covering a wide range of behavior. These components are
  \citet{Fontaine2007} argue, appraisals of events,
  psychophysiological changes, motor expressions, action tendencies,
  subjective experience, and emotion regulation
  \citep{Fontaine2007}. The antecedents of emotions are equally
  varied as the consequents and may be both internal as well as
  external \citep{Scherer2005}.

  One important adaptive function of emotions is regulating social
  interactions by facilitating group cohesion and
  collaboration. Understanding the emotions of others is an essential
  aspect of many social situations. \parencite{Niedenthal2012}.

  The ability to process the emotional information contained both in
  the self and in others has been referred to in the literature as
  emotional intelligence
  \citep[see~][for~an~early~example]{Salovey1990}. Emotional
  intelligence has over the last quarter of a century gained the
  attention of researchers and has become, as we shall see, a somewhat
  controversial matter. The ability encapsulated in emotional
  intelligence can be conceptualized as differences in the extent to
  which organisms interpret, process and act upon the emotions and
  affects of themselves and others. An essential component in
  emotional intelligence seems to be the ability to identify the
  emotions of oneself and others, with other cognitive-social
  abilities depedending on this base. \citep{Mikolajczak2014}

  The concept of emotional intelligence, however, is not
  uncontroversial. Various different authors with different approaches
  suggest widely different models of emotional intelligence
  \citep[][e.g.~]{McCleskey2014,Mayer2008,Petrides2010}. Other authors
  (TK, Who? Locke surely) have questioned the validity of emotional
  intelligence. Supporting a more limited notion emotional
  intelligence, some studies have found emotional intelligences to
  correlate with personality factors
  \citep[e.g.][]{Warwick2004,Petrides2001} and cognitive abilities
  \citep[e.g.][]{Freudenthaler2007}. These results call into question
  the divergent validity, to that point of some authors (TK Locke and
  someone else) doubting overall usefulness of the concept.

  Despite the controversy related to the concept itself, several
  approaches have been used to measure emotional intelligence, both
  ability tests \citep{Mayer2003}, self-reported ability
  \citep{Bar-On1997}, and personality trait measures
  \citep{Petrides2007}.  Various different methods have also been
  developed for measuring emotional intelligence. For example,
  \citet{Mikolajczak2014} approached the measuring of emotional
  intelligence and developed a 50-item inventory for emotional
  intelligence. \citet{Baron-Cohen2001} approached the problem from a
  different vantage point, asking participants to identify an emotion
  based just on a picture showing a pair of eyes. Another strand of
  research focuses on measuring emotional facial recognition
  \citep{Schlegel2012}. The results of \citet{Schlegel2012} seem to
  indicate that the recognition of emotional faces is a single ability
  as opposed to multiple separate abilities, affirming to some degree
  the convergent validity to the construct of emotional intelligence.

  Another approach that might be taken for emotional intelligence
  testing is using emotional facial expressions in a manner similar to
  \citet{Schlegel2012}, where the ability to classify emotional facial
  expressions was used. The ability recognize emotions in the faces of
  others seems to be an important social ability
  \citep{Ekman2003}. This suggest facial expression recognition
  ability could be seen as a measure of general emotional
  intelligence.

  Facial expressions, \citet{Ekman1969a} found, are to a large extent
  culturally invariant, a prerequisite for valid measure of emotional
  intelligence. The set of culturally invariant basic emotions
  \citet{Ekman1992} later defined as anger, fear, sadness, enjoyment,
  disgust and surprise.

  Cultural invariance is an important property for tests of emotional
  intelligence. Based on the evidence for cultural invariance of
  emotional facial recognitions it seems that facial-expression
  recognition may be an appropriate measure of emotional
  intelligence.

  \citet{Ekman1974a} introduced the brief affect recognition task
  (BART) as a means by emotion recognition can be measured. One trial
  in the BART paradigm consists of a display of an emotional facial
  expression with forward- and backward masks of a neutral emotional
  face to provide a fixation and avoid after-images respectively \citep{Ekman1974a}.

** Research problem
   Testing and training applications are a central part of
   micro-expression research \citep{Ekman1992}. However, despite
   multiple several studies being made \citep[e.g.][]{Schlegel2012},
   there exists no standard for emotional intelligence focused on
   emotion recognition. Likewise, earlier approaches have focused
   solely on emotion recognition.

   The lack of a standard test of emotion recognition and emotional
   intelligence, may be indicate a lack of understanding of what
   factors are important for developing tools for testing emotional
   intelligence.

   The present study sets out improve the understanding of how such
   testing software could be designed and developed, aiming to improve
   the accuracy and availability of such tests by developing such an
   artefact.

   The creation of such a test could be relevant for a number of
   areas. Firstly, education of psychologists, psychotherapists, and
   other mental health professionals might benefit from improved
   training tools, likewise applications can be found for training
   police and other law enforcement professionals. Second,
   applications in recruiting situations may help organizations make
   better recruitment decisions. Finally, psychological tests using
   the micro-expression paradigm may be improved based on the
   development of new tests.

** Research question
   What are the key principles for developing EQ-tests based on micro-expressions?

* Extended background
  In the extended background a number of theoretical models,
  applications, earlier tests and stimulus sets are reviewed an are
  discussed. These lie at the foundation of the artefact developed in
  the present study.
** The Theoretical Models of Emotional Intelligence
   The definition of emotional intelligence has since its inception
   been the subject of fierce debate \citep{McCleskey2014}. One of the
   key sources of controversy is whether emotional intelligence is to
   be considered an ability \citep{Salovey1990}, a competency that can
   be learned \citep{Baron2006} or personality trait
   \citep{Petrides2007}. This disagreement on the definition of the
   concept may at first seem superifical but lies at the core in the
   issue of measuring, understanding and applying theories of
   emotional intelligence.(TK Something about Goleman model)

   The notion of emotional intelligence as a competency is primarily
   advocated by \citep{Baron2006}. The Bar-On model, defined more
   precisely as a "cross-section of interrelated emotional and social
   competencies, skills and facilities that determine how effectively
   we understand and express ourselves, understand others and relate
   with them, and cope with daily demands" \citep{Baron2006}. The
   model is consistent with other frameworks and includes both inter-
   and intra-personal skills. Like most other models of emotional
   intelligence, the Bar-On model considers a set of widely different
   situations and criteria, ranging from the recognition of emotions
   to the regulating emotions. \citep{Baron2006} This model was
   introduced in (TK, doctoral dissertation).

   Writing only years after Bar-On (TK, Doctoral dissertation)
   \cite{Salovey1990} introduced their notion of emotional
   intelligence, with the widely cited \citep[][e.g]{McCleskey2014}
   passage defining emotional intelligence as ``the subset of social
   intelligence that involves the ability to monitor one's own and
   others' feelings and emotions to discriminate among them and to use
   the information to guide one's thinking and actions''.
   Additionally, \citet{Salovey1990} divided emotional intelligence
   into four sub-categories of emotional intelligence: appraisal,
   expression, regulation and, utilization. Thereby defining the
   boundaries of the subject.

   Furthermore, \citet{Salovey1990} argue that people exhibiting the
   four abilities may show more adaptive behaviors in social
   situations. This was later expanded in
   \citet{Brackett2006}. Conversely, people exhibiting deficits in
   emotional intelligence may show maladaptive behaviors
   \citep{Brackett2006}.

   Beginning with \citet{Petrides2001}, one strand of research has
   separated emotional intelligence into trait and ability components
   \citep[e.g.][]{Petrides2007, Petrides2010}. Indeed, a growing body
   of evidence seems to indicate that personality factors explain some
   parts of emotional intelligence
   \citep[e.g.][]{Warwick2004,Petrides2001}. Specifically,
   \citet{Warwick2004} found correlations between personality factors
   and trait emotional intelligence.

   Building on these results \citet{Petrides2007}, argues that while
   trait emotional intelligence is a personality trait and
   uncorrelated with ability measures of emotional intelligence, it is
   distinct from traditional personality factors.

   The incompatibility argument is expanded further by
   \citet{Petrides2010}, arguing that trait and ability measures of
   emotional intelligence cannot be grouped in any meaningful
   sense. Moreover, \citet{Petrides2010} criticizes the Bar-On
   \citep{Baron2006} model as well as the \citet{Salovey1990} model,
   arguing that ability measures of emotional intelligence imply the
   existence of some universal notion of adaptive social
   behavior. Such a notion of imply a culturally invariant concept of
   socially appropriate, or intelligent behaviour, which is difficult
   to establish.

   To resolve some of the controversies surrounding the definition of
   the term \citet{Cherniss2010} suggests separating the concepts of
   emotional intelligence and social competence. \citet{Cherniss2010}
   defines emotional intelligence simply as recognizing, reasoning and
   regulating emotions, holding that other factors are simply
   emotional and social competencies, building on the ones emotional
   intelligence. In effect \citet{Cherniss2010}, designates the
   \citet{Salovey1990} model as emotional intelligence, while
   referring to the Bar-On model \citep{Baron2006} as emotional and
   social competence. This attempt to reconcile the two major theories
   of emotional intelligence was criticized by \citet{Petrides2010}
   for severing the link between the constructs and their present
   operational definitions. Doing so, \citet{Petrides2010}, argues
   would cause a disconnect between what is actually studied and what
   the definition used is.

   The separation of trait and state concepts of emotional
   intelligence is supported by most authors
   \citep[e.g.][]{Petrides2010,McCleskey2014,DiFabio2014} (TK,
   Askhanasy). What this separation entails, however, is a matter of
   debate. Proponents of the trait model of emotional intelligence
   such as \citet{Petrides2010} argue that ability measures of
   emotional intelligence are lacking.  On the other hand proponents
   of the ability model argue that trait models just measure various
   aspects of personality.

   Another approach was taken by \citet{Freudenthaler2007},
   interpreting trait and ability as typical and maximum performance
   respectively. \citet{Freudenthaler2007} finding that typical
   performance is dependent on personality and that maximum
   performance is dependent on some cognitive ability. This model has
   the advantage of being better aligned with the approach taken for
   other cognitive abilities, and not being specific to emotional
   intelligence.

   Having seen multiple different definitions of emotional
   intelligence, what little agreement exists could perhaps be
   captured as follows: emotional intelligence is a continuous factor
   determining the depth and accuracy of processing at the crossroads
   of emotion and cognition.

   Even if earlier intergrative approaches have been critized
   \citep[e.g.~][]{Cherniss2010}, multifaceted approaches may still be
   valuable, however this would require combining the theoretical
   multiple theoretical frameworks. For any psychometric test to be
   useful, it needs to be loosely coupled to its theoretical concepts,
   while retaining internal cohessiveness, developing tests based on
   the insection of theoretical frameworks may therefore make a test
   independent of which framework prevails.

** Practical Applications for Emotional Intelligence

   Desipte the difficulty of accurately defining the term, proponents
   of emotional intelligence argue its usefulness.  In a review by
   \citet{Mayer2008} identified seven central results of emotional
   intelligence research, these were:
#+BEGIN_QUOTE
   1. Better social relations for children.
   2. Better social relations for adults.
   3. High-EI individuals are perceived more positively by others.
   4. Better family and intimate relationships.
   5. Better academic achievement. [not accounting for IQ]
   6. Better social relations during work performance and in negotiations.
   7. Better psychological well-being.
#+END_QUOTE

   Within the areas discussed by \citet{Mayer2008}, it seems that
   measures of emotional intelligence, have some predictive
   validity. Indeed, the results within the aforementioned areas
   suggest that tests and instruments measuring emotional intelligence
   may be practically applicable.

   Another often discussed area is the relationship of emotional
   intelligence and leadership. It is commonly held that emotional
   intelligence plays a role in leadership
   \citep{Brackett2006,McCleskey2014}. \citet{McCleskey2014} argues
   that for at least some aspects of leadership, it seems likely that
   emotional intelligence offers some predictive value for performance
   leadership roles \citep{McCleskey2014}. This could make emotional
   intelligence an important tool for executive search.

   Moreover, emotional intelligence scales have been used for
   corporate recruiting for roles requiring social interaction. These
   results seem to suggest that emotional intelligence may be useful
   in guiding hiring decisions \citep{McCleskey2014}.

   Additionally, the concept of emotional intelligence is useful in the
   diagnosis and testing for autism spectrum disorders
   \parencite{Baron-Cohen2001}. In this particular case, a specific
   test of emotion recognition, reading the mind in the eyes, was
   developed for this purpose \citep{Baron-Cohen2001}.

   Overall, the evidence seems to suggest that the concept of
   emotional intelligence is applicable to a number of practical
   situations. This would imply a soecietal benefit in the application
   of emotional intelligence.

** Measuring emotional intelligence of Ability

   Like with its definition, how emotional intelligence is measured is
   also debated. There exists no universally accepted standard for
   measuring emotional intelligence. The different tests of emotional
   intelligence usually fall into one of only one of the theoretical
   models of emotional intelligence.

    An early psychometric test of emotional intelligence is the
    Mayer-Salovey-Caruso Emotional Intelligence (MSCEIT), which is
    based on the theoretical framework introduced by
    \citep{Salovey1990}. In version 2.0 it consisted of 141 items
    across four facets of emotional intelligence
    \citep{Mayer2003}. MSCEIT attempts to measure performance based on
    a set of eight tasks, mapping two tasks for each facet
    \citep{Mayer2003}. The tasks used in MSCEIT cover a number of
    different emotional abilities including recognition of emotional
    pictures and faces as well as understanding and managing emotions
    \citep{Mayer2003}. One differentiating aspect of MSCEIT is its
    focus on emotional problem-solving, where test-takers are posed
    with imaginary situations in which emotional intelligence is
    required.

    In an evaluation of MSCEIT 2.0, the second version of MSCEIT,
    \citet{Mayer2003} found both sufficiently reliability as well as
    consistency with its theoretical foundations. This would suggest
    that MSCEIT may be appropriate for research use.

    However, The validity of the MSCEIT has however was later disputed
    disputed. \citet{Rossen2008} found results running contrary to the
    factor structure used found in the validation study by
    \citet{Mayer2003}. The results found by \citet{Rossen2008} seem to
    suggest that the sub-scales do not match the intended theoretical
    concepts, putting the test into question.

    For measuring trait emotional intelligence, \citet{Salovey1995}
    introduced Trait meta-mood scale (TTMS) which aims to measure the
    tendency to attend to one's moods and emotions. The TTMS test has
    been found not to correlate with MSCEIT, indicating that it is a
    separate construct from ability measured by MSCEIT
    \citep{Warwick2004}. The TTMS is meant to capture differences in
    the tendencies to engage in socially intelligent behaviour, which
    are not explained by ability model \citep{Salovey1995}.

    Self-reported psychometric tests have also been for measuring
    ability emotional intelligence, one of these is the Profile of
    Emotional Competence (PEC), which consists of 50 items divided
    into ten sub-scales \citep{Brasseur2013}. The PEC shows a good
    internal consistency, making it appropriate for both clinical and
    research use \citep{Brasseur2013}.

    Recently, \citet{Mikolajczak2014} were able to reduce the earlier
    PEC scale to only 20 items while maintaining the to a large degree
    the accuracy of the original 50-item scale. This result suggests
    that emotional intelligence can be measured using only a small
    number of questions.

    Another method of measuring is Emotional Quotient-Inventory
    (EQ-I), a standard questionnaire consisting of 131-items divided
    five sub-scales with three facets each for a total of 15 ratings
    \citep{Bar-On1997}. The EQ-I is built on the theoretical framework
    based on emotional intelligence as a competency
    \citep{Baron2006}. EQ-I is often used both on an individual and a
    peer-level, where peers are asked to rate the individual's
    emotional intelligence \citep{Bar-On1997}. The approach of using
    peer ratings has recently found support in \citet{Elfenbein2015},
    showing that such peer ratings can be both accurate and reliable.

    The Emotional Quotient Inventory (EQ-I) is not without its
    problems. A big problem is that of fakeability, one study
    conducted by \citet{GrubbIII2007}, found that participants when
    asked to "fake" emotional intelligence were easily able to do
    so. Such fakeability is quite troublesome because it would imply
    that the EQ-I does not measure a competency, because an ability
    would have been difficult to fake.

** Measures related to Emotional Intelligence

   Outside the development of psychometric tests of emotional
   intelligence, some research has also gone into examining other
   aspects and ways of measuring emotional intelligence and related
   areas. Over time, a wide variety of tests have been developed for
   assessing emotion intelligence and related concepts. These tests
   are often developed outside the area of emotional intelligence, and
   are to some degree unaffected by the controversy surrounding other
   measures of emotional intelligence.

   One measure that might be considered emotional intelligence is the
   reading the mind in the eyes (RTMITE) test \citep{Baron-Cohen2001},
   which has been successful in distinguishing people with Asperger
   Syndrome and high-functioning autism from controls. The instrument has
   shown good test-retest reliability \citep{Hallerback2009} and has
   been applied in a number of cultures
   \citep{Yildirim2011,Hallerback2009}.

   Another measure related to emotions is the Toronto Alexithymia
   Scale (TAS), a 20-item test aiming to detect alexithymia. The TAS
   consists of two subscales: difficulty identifying feelings and
   difficulty describing feelings \cite{Bagby1994}. The measure has
   shown good validity \citep{Bagby1994}. Further evidence for its
   validity were found by \citet{Bressi1996}, showing that good
   validity could also be obtained for Italian populations, suggesting
   at least some degree of cultural invariance. Finally, in a
   functional magnetic resonance imaging (fMRI) study,
   \citet{Berthoz2002} found differences in the activation of the
   anterior cingulate cortex and the mediofrontal cortex between high
   people with high TAS-scores and controls. These results suggest an
   underlying neural basis for the TAS and alexithymia, in general.

** Emotional Facial Expressions
   A separate but related field to traditional emotional intelligence
   testing is the recognition of emotional facial expressions. This
   strand of research builds on the work of \cite{Ekman1969a}. The
   model of emotions advanced by Ekman identifies a set of basic
   emotions that are culturally independent \citep{Ekman1987}, occur
   automatically \citep{Ekman1992,Ekman1997} and are automatically
   processed \cite{Ekman1992}.

   Another feature of Ekman's model is emotional leakage, which occurs
   when consciously trying to suppress the expression of some emotion
   \citep{Ekman1969,Ekman2003}. This emotional leakage, what Ekman
   refers to as micro expressions can be identified by others
   \citep{Ekman1974}.

   Both individual and group differences in the ability to detect
   deceit have been found. For example, \cite{Ekman1991} found that
   some professional groups (e.g. the U.S. Secret Service) are better
   at detecting deceit, using both verbal and non-verbal cues
   \cite{Ekman1991}.

   Another important result is that of \citet{Frank1997}, which seems
   to suggest that the ability to detect deceit is generalized to a
   large number of situations. This lends validity a central concept
   as the cues used to detects deceit.

   #+BEGIN_LATEX
   \begin{figure}[htpb]
   \centering
   \label{fig:mett}
   \includegraphics[width=0.5\textwidth]{diamett}
   \caption[Visual representation of the METT paradigm]{One complete trial in the METT paradigm, consisting of a forward mask, a stimulus and a backward mask. The pictures used in this example are taken from the KDEF data-set.}
   \end{figure}
   #+END_LATEX

   Based on this theoretical framework \cite{Ekman1974a} introduced
   the Brief Affection Recognition Test (BART), consisting of very
   brief displays of emotional facial expressions (under
   200ms). Paradigms based on the BART been widely used
   \cite[e.g.][]{Matsumoto2000}. By only showing the facial expression
   for a short time, accuracy of identification is reduced as compared
   to longer exposure times. Ensuring that the chance-adjusted is as
   close to 50% as possible is important to avoid floor and ceiling
   effects. Floor and ceiling effects should be avoided as they could
   distort the data. An important feature of BART is its use
   masking images of neutral faces both before and after a trial
   \citep{Ekman1974a}. This masking serves both to provide a fixation
   point before the trial, and ensure that the participants do not
   have the benefit of after-images. This paradigm is illustrated in
   \ref{fig:mett}

   Another method of ensuring low enough accuracy is the subtle
   expression training tool (SETT). Unlike the BART, expressions are
   restricted to one part of the face. This restriction is meant to
   simulate a situation where the person is consciously suppressing a
   facial expression. \citep{Ekman2003}

** Stimulus sets of emotional facial expressions

   To use the paradigms discussed it is necessary to use a set of
   photographs. Because recognition of facial expressions is a common
   task there exists a plethora of facial expression stimulus
   sets.

   These stimulus sets have been created for a number of
   different purposes and are suitable for many different kinds of
   research. For the present study, a number of different stimulus
   sets and the research surronding them was reviewed. The stimulus
   sets reviewed in the present study by no means represent a complete
   coverage of all stimulus sets created, however it aspires to a
   sufficent coverage of the stimlus sets in common use.

   One early stimulus set is the Japanese and Caucasian Facial
   Expressions of Emotion \citep[JACFEE;][]{matsumoto1988japanese}.
   JACFEE consists of 56 photos of models of Japanese or Caucasian
   decent with eight pictures, one for each basic emotions, and one
   neutral picture \citep{matsumoto1988japanese}. The dataset, while
   showing some cross-national differences also showed relatively high
   levels of agreement \citep{Biehl1997}.

   Another commonly used data-set of emotional facial expression is
   the Karolinska Directed Emotional Faces
   \citep[KDEF;][]{DanielLundqvistAndersFlykt1998}. KDEF consists of
   pictures 70 of individuals expressing seven different emotions from
   five angles. KDEF has, since its inception, seen much use in facial
   expression research
   \citep[e.g.][]{Calvo2008a,Willis2006,Todorov2009}. In addition to
   its widespread use, KDEF has shown good test-retest validity and a
   high degrees of accuracy in recognition tasks
   \citep{Goeleven2008}. Such results are indicate that the stimulus
   set is appropriate for research use.

   \citet{Beaupre2000} approached the issue of finding a good stimulus
   set from the perspective of cultural difference in the ability to
   recognize emotions. The Montreal Set of Facial Displays of Emotion
   \citep[MSFDE][]{Beaupre2000} consists of facial expressions where
   the actors were instructed to pose facial expression based on the
   facial action coding scheme. The full stimulus set consists of 144
   images, with six types of facial expressions and three ethnic
   groups: French Canadians, Chinese, and sub-Saharan Africans.  The
   MSFDE was validated in \citet{Beaupre2005} and showed to exihibit a
   large degree of cultural invariance.

   Yet another set is NimStim \citep{Tottenham2009}, consisting of 672
   images of 43 professional actors instructed to pose eight different
   emotions with expressions of both open and closed mouthed
   expressions. In their evaluation \citet{Tottenham2009}, found that
   the reliability of the set was good. They also selected a
   recommended subset of the images for which reliability is good, for
   use in future studies.

   A more recent contribution is the Radboud Faces Database
   \citep[RaFD;][]{Langner2010}. RaFD contains photographs of 49
   models expressing eight emotions with three gaze directions, taken
   from five camera angles for a total 5880 photographs
   \citep{Langner2010}. Upon validation, RaFD showed a very high
   accuracy, higher even than the earlier KDEF dataset
   \citep{Langner2010}. A key difference between RaFD and KDEF, which
   perhaps explains the difference in accuracy is the expression
   coaching given to models by a facial expression coding expert
   \citep{Langner2010}.

   \citet{Calvo2008a} investigated the relationship between the
   presentation time (25-500ms) and the accuracy of emotion
   recognition in a non-masked emotion recognition paradigm, with the
   KDEF stimulus set, and found a slight increase in accuracy for
   longer displays. In addition, \citet{Calvo2008a} found differences
   in detection between the emotions. Happy and neutral showed higher
   degrees of accuracy than the other emotions and fear showed a lower
   accuracy.

   The results of \citet{Calvo2008a} suggest that there are
   differences in the accuracy of processing different emotions. Most
   importantly, it seems that accuracy rates for facial expressions of
   happiness and neutral expressions are much higher than those of
   other the expressions \citep{Calvo2008a}. Care must, therefore, be
   taken so as to avoid ceiling effects in general and happiness in
   particular.

   Another strand of research has gone into the split-second trait
   judgments made viewing a face. \cite{Willis2006} found very strong
   correlations between judgments of trustworthiness made after
   \SI{100}{\milli\second} or \SI{500}{\milli\second} versus those
   made without any time constraint. Moreover, no significant
   difference was found between the \SI{100}{\milli\second} and
   \SI{500}{\milli\second} conditions, suggesting that a trait
   judgment is performed very quickly. This notion was further
   expanded by \citet{Todorov2009}, finding that grew accuracy with
   display times up to \SI{100}{\milli\second}, after which the growth
   rate is dramatically slower. These results are important as they
   seem to indicate the depth of processing of faces that occurs even
   at low presentation times.

   One problem shared by all stimulus sets discussed here is that they
   consist only of still images of facial expression. It could be
   argued that the dynamics of facial expressions play an important
   role in the recognition of facial expressions. Indeed, this is the
   way in which emotional facial expressions play out in nature. This
   problem has lead to the development of a number of video-based
   stimulus-sets for facial expression. The Geneva Multimodal Emotion
   Portrayals \citep[GEMEP;~][]{Banziger2012} is one of these. The
   GEMEP utilizes contains audio and video for each expressions
   providing three options for stimulus displays, audio-only,
   video-only, audio-video. Moreover, The GMEP stimulus-set is extensive, with a
   total set of 1260 expressions, spread out over eighteen emotions,
   ten actors, three angles and a varying number of repetitions and
   different verbal content \citep{Banziger2012}.

   Based on the research discussed in this review, it could be argued
   that measuring the recognition facial expressions may be successful
   in finding individual differences in emotional processing. This
   difference seems particularly pronounced at presentation times
   shorter than one second.

* Methodology and Methods for Data Collection
   The goal of the present study is not merely empirical, it aims also
   to design a computerized test of emotional intelligence. The
   distinction between design science and normal research isdiscussed
   further by \citet[chapter~1]{Johannesson2014}, who hold that
   practical problems ought to be addressed with design research
   approaches.

   \citet[chapter 4]{Johannesson2014} put forward a model of design
   science based on five activities. The first activity, Explicate
   Problem, aims to find the practical problems that needs
   solving. The second activity Define Requirements, finds what
   requirements should be included in the artefact. The third stage,
   Design and Develop artefact concerns the creation of the actual
   artefact. The fourth stage, Demonstrate Artefact aims to
   demonstrate that the artefact solves the actual problem. Evaluate
   artefact where the extent to which the artefact solves the intended
   problem.

   By using these stages, \citet{Johannesson2014} argue that the
   successful application helps researchers decide on a what to
   develop, develop an artefact and evaluate it.

   Another approach to design science is that of \citet{Hevner2007}
   consisting of three cycles, the Relevance cycle, where the subject
   area an its requirements are identified, the design cycle where the
   artefact is designed and deployed. Finally, in the rigor cycle, the
   applies and grounds the developed artefact in existing theories,
   perhaps resulting in meta-artefacts. \citep{Hevner2007}

   The paradigm presented by \citet{Hevner2007} is different in many
   aspects from that of \citet{Johannesson2014}. Where as
   \citet{Johannesson2014} emphasize a larger set of well-defined
   activities, \citet{Hevner2007} put forward a less structured set of
   phases which are to be performed iteratively.

   Different from the methods of both \citet{Johannesson2014} and
   \citet{Hevner2007} is the design science method introduced by
   \citet{Peffers2008}. Design science, in the paradigm of
   \citet{Peffers2008} has six stages, conducted iteratively. The
   stages described in \citet{Peffers2008} are:

   - Identify Problem & Motivate
   - Define Objectives of a Solution
   - Design & Development
   - Demonstration
   - Evaluation
   - Communication
   The model allows any stage of the design process as the entry point
   for research process. Making the process fit better with actual
   practice.

   While the methodology of both \citet{Hevner2007} and
   \citet{Peffers2008} show promise, the stages presented by
   \citep{Johannesson2014} better fits domain of the present study.

** Chosen stages
   Because of limitations in scope for the present study, only a
   subset of design science activities were performed in the present
   study. The stages chosen for the present study were selected made
   to ensure that a viable, meaningful artefact could be developed
   developed. The design science stages not selected were not
   considered for reporting or practical purposes but were instead
   left out entirely. Because they are the fastest way to reach an
   actual artefact given the limitation in scope, the following stages
   were selected:
   - Requirements definition
   - Implementation
   - Evaluation

** Choice of Method
   For each chosen stage in the design science process, different
   methodological considerations were made. These are discussed
   separately below.  For the purposes of the present study a number
   of approaches were considered. \citet{Denscombe2010} covers a
   number of research strategies.

*** Requirements definition
    For defining requirements an extensive number of research methods
    can be used. Many popular approaches directly involve potential
    stakeholders directly \citet[chapter 6]{Johannesson2014}. One
    oft-used method is surveys allowing for coverage of potential
    requirements \citep[chapter 6]{Johannesson2014}.

    Using surveys runs the risk of not being able to find innovative
    requirements because the stakeholders themselves are sometimes
    unable to identify any requirements sufficently dissimilar from
    the present solution.  \citet[chapter~6]{Johannesson2014} suggest
    using other methods such as case studies and action research to
    find requirements that the stakeholders were unable to
    identify. These methods however have the drawback of applying the
    researchers personal views on the requirements
    \citep[chapter~6]{Johannesson2014}.

    The domain of the present study is complex. Test-takers are
    unlikely to understand the intricate nature of the subject area,
    and their interests do not align with the people administering the
    test. Similarly, practitioners do not always possess a sufficent
    understanding of the tests being administerd.

    Finally, it is difficult to find a significantly large population
    of researchers on the area to establish qualitative
    saturation. This would in the view of
    \citep[chapter~6]{Johannesson2014} restrict the studies to
    documents.

    It could be argued that using only documents would be sub-optimal
    for many IS studies. In the case of the present study the
    situation is for the aformentioned reasons very different.

    To successfully capture the requirements for the present study
    two methods were chosen:
   - A literature review of emotional intelligence and methods of
     testing it.
   - A quantitative analysis of existing data collected from earlier
     applications of a micro-expression test.

   These two methods were chosen to successfully capture variance from
   both the scientific literature as well as empirical data. The
   combination of different kinds of methods may allow for better
   capturing the relevant aspects of emotional intelligence and
   reaching sufficient coverage of the domain.

   The literature review was chosen to ensure a sufficient degree of
   qualitative coverage of the area of research. A wide qualitative
   coverage is particularly important because of the controversial
   nature of the concept of emotional intelligence. This wide coverage
   allows for finding a reasonably agreed upon definition of emotional
   intelligence, which is neccessary for the developed artefact to be
   useful.

   The quantitative analysis of earlier data constitutes experimental
   method \citep{Denscombe2010}, for the reason that the data was
   collected in an experimental settings. The existence of prior data,
   motivates the choice of quantitative analysis of data gathered by
   experimental methods, because this data is already collected using
   it has very low costs. Analysis of such data would allow for
   empirical answers to questions which may be relevant for the study.

   By combining an explorative literature study, giving insights into
   various different areas of emotional intelligence, with an
   empirical analysis of earlier data, the present study can define
   requirements based both on precise facts about the domain as well
   as being able to use insights spread out across the
   literature. This combined strategy is likely to give a both broad
   and deep coverage of the domain.
*** Implementation

    A large number of processes for the implementation of software
    artefacts have been devised. Early research was largely focused on
    very formalized processes, and less formal methods of software
    development were to a point largely ignored. These methods were
    often misaligned with how software development is done in
    practice. Counteracting this a number of agile software
    development processes have
    appeared. \citep{Abrahamsson2002}. Better alignment between
    practice and process may yield better results.

    \citet{Abrahamsson2002} discuss a number of methods, perhaps most
    prominent among which are XP, Crystal, RUP and Scrum. These
    methods all recommend only implementing suggested processes if
    they are useful to the project \citep{Abrahamsson2002}

    With the turn of the millenium, research attention started to
    shift towards agile processes \citep{Dingsoyr2012} These processes
    have become commonly in both academic projects and in the industry
    \citep{Dingsoyr2012}. In a pair of case studies
    \citet{Middleton2002} established that reductions in requirements
    and processes that did not build end-user value could reduce
    error-rates in an artefact.

    With the research consensus being that processes should be enacted
    based on as needed basis it seems resonable for a project with
    little need for formal process to use very little formal process.

    For the implementation of the artefact an unstructured iterative
    development process was used. The process choice was made because
    the scope of the project was small, applying more complex
    processes may well result in problems. The development process
    continued continously until the developed artefact fullfilled the
    requirements identified.

*** Evaluation
    The evaluation of developed artefact was performed using
    experimental methods. Experimental methods are often used for the
    verification of psychometric instruments. Because experimental
    methods are a common method this makes them a good fit for the
    present study. The goal with the developed psychometric test is
    generalization. By controlling irrelevant factors to the greatest
    extent possible researchers are better able to establish
    generalizability. This could, of course, reduce the ecological
    validity of the instrument. The reduction on ecological validity
    is a problem shared by many psychometric instruments, and
    therefore not a problem particular to the present study.

* Application of Method
** Requirements defintion
   For the literature review, a number of research publications
   related to emotional intelligence were reviewed. Based on these
   qualitative coding based analysis was performed. Different
   psychometric measures of emotional intelligence where coded based
   on theoretical models, scales and sub-scales. Similarly,
   stimulus-sets were coded based on the number of models, the number
   of models, emotions used, ethnicities represented etc. Based on
   these a number of criteria were identified.

   For the quantitative data analysis a data from a number of studies
   was used (presented in Table \ref{listofstudies}). Each data-set was then
   analyzed separately. All the studies whose data was analyzed used
   the METT paradigm, and followed a similar protocol, making them
   reasonably comparable.

   For the first study, overall hit-rates and descriptives were
   computed. After computing overall statistics, a confusion matrix
   was then created and a set of variables related to the signal
   detection theory were computed. These variables are all derivable
   by using four variables: $H$, the number of hits (true positives),
   $CR$, the correct rejections (true negatives), false alarms $FA$
   (false positives), and misses $M$ (false negatives).

   \begin{equation} \label{e_hr}
   \mathit{HR} = \frac{H}{H + M}
   \end{equation}

   Equation \ref{e_hr} defines the Hit-rate, also called the
   True-postive rate or recall.

   \begin{equation} \label{e_crr}
   \mathit{CRR} = \frac{CR}{CR + FA}
   \end{equation}

   Equation \ref{e_crr} defines the Correct rejection rate, sometimes
   referred to as specificity.

   \begin{equation} \label{e_ppv}
   \mathit{PPV} = \frac{H}{H + FA}
   \end{equation}

   Equation \ref{e_ppv} defines the positive predictive value.

   \begin{equation} \label{e_npv}
   \mathit{NPV} = \frac{CR}{CR + M}
   \end{equation}

   Negative predictve value is defined according to Equation
   \ref{e_npv}.

   \begin{equation} \label{e_balanced_accuracy}
   \mathit{BalancedAccuracy} = \frac{HR + CRR}{2}
   \end{equation}

   Equation \ref{e_balanced_accuracy} defines the balanced accuracy.

   For the second study, per-trial data, for the psychotherapist group
   was extracted. A cross tabulation of hits and misses for each trial
   was constructed such that the number of hits and misses by trial
   number could be investigated. This data was entered into a linear model.

   Finally, the results of the literature review and the quantitative
   analysis of earlier data were integrated to create requirements for
   for the artefact.

\input{summaryearlier.tex}

** Implementation
   The software artefact designed for the present study was developed
   incrementally in iterations aiming to fullfill a growing subset of
   the requirements. No single development process was selected
   instead a number of practiceses were selected to guide the
   development process.

   This sort of explorative process allows
   developers to better adapt the software being developed as their
   understanding of the requirements grows.

   Automated unit-tests were devloped in an ad-hoc manner as part of
   the overall development process and aimed primarily as an aid
   during the development process.

   An application was developed using the PsychoPy library
   \citep{Peirce2007}. PsychoPy is a module designed for the Python 2
   programming language, aimed at providing functionality for building
   psychological experiments. The PsychoPy library was used because it
   offers excellent accuracy in the presentation of
   stimuli. Additionally, PsychoPy has excellent data collection
   components allowing for greater ease of data processing.

** Evaluation

*** Participants
   The participants ($n=81$), all university students took part in the
   experiment as part of fullfilling a course requirement. The mean
   age of the participants was XXX and the standard deviation was.  Of
   the 81 partipants, 31 took the test twice.

*** Apparatus
    The software under evaluation was executed on laptop PC (TK model
    number here) running the Windows 7 operating system. The
    experiment software was run under the PsychoPy 1.82
    environment. No noticable performance issues were identified with
    the program.

*** Procedure
    Participants were positioned at a distance of approximatly 70 cm
    from the screen. The designed software artefact was then run. The
    test software was configured to run a set of 70 trials and the
    question module configured to gather responses for the SPEC set of
    questions. After completing the experiment, the group taking
    taking the test twice were contacted and another test session
    scheduled.

*** Data-analysis
    Data was analysed using the both the R programming langauge
    \citep{R2015} and statistical environment, as well as a
    Python-based environment using SciPy \citep{SciPy} for statistical
    analysis, iPython \citep{IPython} for reproducable analysis and
    Pandas \citep{mckinney-proc-scipy-2010} for data management.

**** METT-related analysis
     After reading data from disk and combining them, hit-rates and
     descriptives statistics were computed. The number of participants
     completing the test without misses for a certain emotion were
     computed. Kernel density estimates were used for visualizing the
     distributions.

     Split-half reliability measures of correlation for the complete
     data-set by spliting it at the 35th trial. For the 31
     participants who took the test twice test-retest reliability was
     computed, using Pearson's $r$. The fraction and number of
     participants who correctly identified each stimlus was
     computed. Kernel density estimates per emotion were also created.

     For analyzing effects of learning a linear model with a
     trialnumber as the predictor was constructed.

**** SPEC-related analysis
     First, inversions of items and subscales were computed,
     afterwards descriptive statistics were computed for the overall
     scale as well as the subscales. Correlation between each subscale
     were computed, and finally between the METT results and the the
     SPEC.

** Ethics
   Participation in the study was entirely voluntary, and participants
   signed informed concent forms prior to participating in the
   study. No identifying information was collected during the course
   of the study. As the study was performed persuant to a Master's
   degree the study was not submited for external ethical review.


* Results
** Requirements Definition
*** Literature Review
    From reviewing the literature, a number of methods for measuring
    emotional intelligence were found, these are presented in table
    \ref{table:paradigms}. The methods discussed earlier cover many
    different aspects of emotional intelligence, and considers more
    tests than can realistically be used for single experimental
    study, and as we shall we a subset of these will be selected for
    the evaluation.

    \input{paradigms.tex}

    In addition to general test the different stimulus sets were
    considered. These stimulus sets are present in a tabular form in
    table \ref{table:stimsets}.

    \input{stimsets}

*** Analysis of old data
    Each of the data-sets used in the study were analyzed separately
    with the goal the goal of identifying characteristics of the data,
    which was used to identify possible requirements for the system.

    The first data-set contains 2149 correct responses and 1351
    incorrect responses for a total of hit-rate of 61%. A confusion
    matrix was computed as shown in table \ref{study1confusion}. In
    table \ref{study1classtable} characteristics for each emotion are
    shown. Expressions of disgust have, by far, the lowest balanced
    accuracy, participants were unlikely to answer disgust. Anger was
    the most accurately detected emotion, owning to a high degree of
    overall detection.

    \input{study-one-hitrates-emotion.tex}

    The second data-set consisted of 72 participants, each taking the
    form of a , the average accuracy was $72.99\%$ ($S=12.14$).

    #+CAPTION: Hit-rates and standard deviations by emotion in study 2.
    #+ATTR_LATEX: :environment tabulary :align lll :width \textwidth
    | Emotions  |  $HR$ |   $S$ |
    |-----------+-------+-------|
    | Disgust   |    64 | 25.98 |
    | Happiness | 90.05 | 18.98 |
    | Surprise  | 90.85 | 14.37 |
    | Anger     | 79.15 | 20.87 |
    | Contempt  | 57.25 | 33.88 |
    | Fear      | 68.75 | 23.75 |
    | Sadness   |  60.9 | 26.26 |

    To investigate the effects of training, a linear model was
    constructed for the constructed with the number of trials as the
    independent variable and the hit-rate as the dependent variable. A
    significant effect of trial number was found ($t=4.56$, $p<0.001$,
    $df=68$). This effect indicates that accuracy improve throughout
    the experiment itself.

*** Requirements

    In reviewing earlier research we found a number of suitable tests
    for emotional intelligence. Many of the standard measures of
    emotional intelligence are highly controversial. The least
    controversial measure is perhaps the METT, falling outside the
    traditional distinction of trait and state emotional
    intelligence. Another benefit is that the implementations of METT
    in our earlier data seems to possess many beneficial
    characteristics for such a test.

    It is, however, unlikely that emotion recognition tasks can
    capture every aspect of emotional intelligence, some variance may
    be captured using other methods. On the other hand, using too many
    inventories may lead to a measure that takes too long to complete,
    reducing the reliability of the measure and increasing
    time-related costs. Therefore, it is important to keep any such
    tests as short as possible.

    MSCEIT, EQ-I, PEC contain a large number of items, which is
    acceptable for standalone use, however using them in conjunction
    with other tests may be unsuitable as it may become overly
    time-consuming. This leaves TAS, RMITE and SPEC suitable as
    suitable candidates. Being a facial expression recognition task,
    RMITE, is very similar to the METT and for this reasons it is
    unsuitable for capturing complementary sources of variance.

    TAS, while showing robustness, maturity and validity, is limited
    in that it only includes sub-factors related to alexithymia, and
    may for this reason be more appropriate for assessing
    disfunctions. Moreover, one of the factors, identifying feelings
    may overlap to some degree of overlap with METT. This makes it
    unsuitable as a supplementary test to METT.

    Considering the aim of capturing qualitatively different factors
    from METT, SPEC may be the most appropriate test. SPEC provides a
    the same number as factors as the longer PEC, while retaining much
    of the reliability. Given the need for wide coverage of emotional
    intelligence factors as well as the time-constraints, given the
    criteria a short testing time, SPEC seems to be the most suitable
    test.

    Having considered all the tests discussed in the literature review.
    Two tests need to be implemented, METT and SPEC. Specifically
    the test should implement a facial-expression tasks and a digital
    questionnaire, configured for METT and SPEC respectively.

    As discussed earlier \citep[recall][]{Calvo2008a} even a small
    difference in the duration of the display time of a METT trial
    affects affects accuracy, particularly at low exposesure times. It
    is therefore important that exposure times are controlled to a
    resonable degree. To ensure this display times need to be
    specified in numbers of frames. This ensures that the intended
    display times necessarily aligns with the refresh rate of the
    monitor, thereby ensuring some degree of accuracy.

    While, there are clear differences in accuracy between different
    emotions, no respect should be taken to emotion types in deciding
    display times because doing so would render the different emotions
    uncomparable, which would limit the insights that can be gained
    from applyning the test.

    Because the experiment process is time-consuming, both for the
    participant and the experimenter, crashes in the software running
    experiments is waste time, and can be frustrating for
    experimenters and participants alike.  It is, therefore, important
    to ensure the system is stable and avoids data loss to a as large
    extent possible given avaliable development resources and scope of
    the present study.

    Additionally, an means of input needs to be selected. Using the
    keyboard is the most suitable input device for the test being
    developed, for several reasons. Firstly, it allows for faster
    responses once the user has learned the options. Second, not
    showing a mouse-cursor would avoid problems stemming from the
    occlusion of the stimulus being presented by the mouse
    cursor. Finally, keyboards are commodity hardware and using them
    removes the need for purchasing specialized input hardware, making
    the test accessible to a wider range of researchers and
    practitioners.

    Another issue is the effects of training, as the results from the
    analysis of earlier data showed, there was a strong effect of
    training ($P<0.001$). Specifically the earlier data showed a clear
    linear training trend. In the data-sets considered in the present
    study no end to this trend was found. The lack of an end, even
    after 70 trials, suggests that training effects are still relevant
    after a substantial number of trials. For this reason, to ensure
    that data gathered using the test is comparable between
    individuals, the number of trials need to be the same for all
    individuals.

    Finally, the issue of stimulus set needs to be addressed. In the
    data from earlier the earlier studies we found that performance
    was inline with what is typical for the METT paradigm, it
    therefore reasonable to assume that there are no additional issues
    with the RaFD data-set used in these. It seems appropriate then to
    use RaFD for evaluating the artefact developed for the present
    study, while leaving data-set as a configurable variable.

    From the conclusions drawn a number of requirements were
    derived.

    1. Requirements pertaining to the METT test
       1. Functional: The system shall display a forward-mask
       2. Functional: The system shall display a backward-mask
       3. Functional: The system shall display a target-image
       4. Functional: The system shall display times shall be precise within  \SI{1/60}{\second}
       5. Functional: The system shall collect selected emotion input via the keyboard.
       6. Functional: The system shall perform the same number of trials for each participant.
       7. Functional: The system shall allow for the configuration of stimulus sets.
    2. Requirements pertaining to the SPEC-test
       1. Functional: The system shall show the questions
       2. Functional: The system shall collect numeric responses via keyboard input.
    3. Requirements pertaining to data collection, endurance and persistance
       1. Functional: The system shall persist results to disk in the CSV format.
       2. Non-functional: The system shall be stable to avoid data-loss
    4. Requirements pertaining to ease-of-use
       1. Non-functional: The system shall be simple to initialize




** Implementation
   #+INCLUDE: "result_implementation.org"

** Evaluation
   The analysis of the data gathered in the study can naturally be
   divided into METT and SPEC-data. In the following sections results
   related to the scales will be presented in turn.
*** Micro-expression Testing Tool
    A total of $4268$ responses were collected, $2977$ of which were
    correct and $1291$ were incorrect, for an overall hit-rate of
    $69.1887\%$ Hit-rates divided by emotion are presented in table
    \ref{table:metthitrate}.

    #+LATEX: \input{metthitrate}

    The number of participants correctly identifying every stimulus of each emotion correctly were
    computed, these are presented in table \ref{table:mettnomiss}

    #+LATEX: \input{mettnomiss}

    Kernel density estimates were computed for each emotion
    separately, these are presented in figure \ref{fig:kde}. Happiness
    and surprise, assuming a normal distribution, have seen large
    restrictions of range.

    #+BEGIN_LATEX
    \begin{figure}[htpb]
    \centering
    \label{fig:kde}
    \includegraphics[width=1\textwidth]{result-analysis/kde}
    \caption[Hit-rate Kernel Density Estimates per Emotion]{Kernel Density Estimates of Hit-rates for each emotion}
    \end{figure}
    #+END_LATEX

    For the 31 participants taking the test twice, the measured
    test-retest correlation of $r=0.8542$ ($p < 0.001$, $df=29$).
    This level of reliability is considered good. ($0.7 \leq r < 0.9$).

    Test-retest correlations for each emotion individually is
    presented in table \ref{table:metttestretest}.  This level may
    however, be deflated by a limitation of range for some
    emotions. Indeed, happiness, which as we have discussed earlier,
    is known to cause ceiling effects, shows a low, non-significant
    correlation. Additionally, surprise and fear show lower
    correlations compared to the other emotions.  Contempt and
    disgusts, on the other hand show higher correlations than the
    other emotions.

    The low correlation for fear is somewhat surprising, given the
    fact that there is no obvious restriction of range discernable
    from visual inspection of the kernel density estimates.

    #+LATEX: \input{testretest}
*** SPEC
    The descriptive statistics for the SPEC subscales are presented in table \ref{table:specdesc}
    #+LATEX: \input{specdesc}

    A correlation matrix was constructed between each of the subscales
    of the SPEC, which is presented in table \ref{table:speccorrmtx}.
    Correlations between each of the subscales and the METT results are
    presented in table \ref{table:specmettcorr}
    #+LATEX: \input{speccorrmtx}

    The test-retest correlation for the SPEC was $r=0.5070$ ($p <
    0.01$, $df = 29$). A test-retest correlation of $r < 0.6$ is
    considered poor. Test-retest correlations of the individual
    subscales are presented in table \ref{table:specmettcorr}.

* Discussion
  The main finding was that developed METT-test showed good
  reliability.  Test-retest scores correlations indicated a good test
  reliaiblity. Additionally the split-half reliability found were
  good.

  The test however, did not avoid the avoid the common ceiling
  effects for happiness. A majority ($72.83\%$) of participants
  correctly identified every single happy emotional face in the METT
  part of the experiment. Indeed, as seen as seen in the kernel
  density estimates presented in figure \ref{fig:kde}, a large portion
  of the distribution for happiness was cut-off. This is indicative
  cieling effects.

  The higher accuracies for expressions of happiness found in the
  present study has also been found in earlier studies
  \citet[recall~][]{Calvo2008a}, the present study confirms these
  earlier results.

  In future iterations such limitations of range need to be
  avoided. The results seem to suggest that if ceiling effects for
  happiness could have been avoided, the test would have had a higher
  reliability. This could perhaps make it more suitable for
  high-stakes testing, which is usually reserved for tests showing
  reliabilities above $0.85\%$ . Interestingly, our results seem to
  suggest that surprise is affected be ceiling effects, and reducing
  accuracy for expressions of surprise is also necessary to increase
  reliability of the test.

  One method for reducing participant accuracy is simply reducing the
  time for which the stimulus is presented. However, some expressions,
  such as fear, where the average hit-rate is lower, may cause floor
  effects instead. This could be solved by using different
  presentation times for different emotions. While using different
  presentation times might improve the overall quality of the test it
  makes the emotions uncomparable.

  A possible focus for future research is to investigate methods for
  minimizing the effects and occurance of range-limitation. A number of
  methods could be implemented to avoid these.

  One possible solution for this would be to have varying display
  times within each emotion, such that the test would include a number
  of different conditions with different presentation times. Such an
  approach would, if calibrated properly, would avoid both floor and
  ceiling effects. Using an adaptive testing procedure such as this
  could improve the test, but is not entirely without related
  development costs.

  Other possible solutions, such as staircase and threshold methods,
  could also be used. In such methods the minimal presentation time to
  achieve a certain level of accuracy for a given indivdual can be
  established. There exists numerous psychophysical methods that can
  be used to establish these.

  Changing the stimulus set to be so as to be more challenging could
  be another option. Most stimulus-sets, including the one used in the
  present study are designed to be easily recognizable (e.g. KDEF,
  \citet{Langner2010}; MSFDE, \citet{Beaupre2000}). It seems likely that
  using a stimulus set where expressions of happiness and surprise are
  less overt could lead to a decrease in ceiling effects.

  Another finding was the relatively low correlations between the
  subscales of the SPEC. This conforms with the earlier results of
  \citet{Brasseur2013} and lends divergent validity of the structure
  of the SPEC and PEC.

  However, the test-retest reliabilty found for SPEC in the present
  study was poor, calling into question the overall reliability of the
  SPEC. One possible cause for the lower test-retest reliability might
  be the translation used in the present study. While there were some
  differences, between the subscales it seems that none of the scales
  reached good reliability. Translation differences are unlikely to
  cause such poor test-retest reliability as the same questions are
  used a both trials. A poor test-retest reliabilty could be
  indicative of a number factors unrelated to the translations the
  actual test. It may be the case that the trait measured in the SPEC
  is not stable, and instead something that varies with mood.

  Additionally, the results of the present study, showing low
  correlations between the SPEC and METT seems to indicated that the
  scales, measure different facets of emotional intelligence. Indeed,
  as discussed in the litterature review SPEC and METT belong to
  different theoretical frameworks of emotional intelligence. It seems
  that the SPEC, measuring a trait, gives very different results as
  compared to the ability based METT.

  Exactly what is measured by trait scales of emotional intelligence
  is debated, at the very least it gives an indication of an
  individuals appraisal of his or her own emotional intelligece.
  On the other hand the poor test-retest correlations found might
  indicate that another test of trait emotional inteligence should
  have been used. Indeed, future research could apply a number of
  different scales, attempting to find one having a higher
  reliability. The artefact developed allows in the present study
  allows for question-sets to be specified in configuration, thereby
  making it trivial to apply the test with different tests.

  Despite the limitations related to expressions of hapiness and
  surprise the artefact developed in the present study offers some
  good properties. The test, being mostly ability-based is robust to
  faking and social desirabilty. It captures both personality traits
  related to emotional intelligence as well as the actual ability to read
  emotional cues in the facial expressions of other's.

  The test developed in the present study has both practical and
  academic uses. The artefact developed, is adaptable to a number of
  different test metodlogies and can be used for both psychological
  research and practical emotional intelligence testing. It also
  provides a foundation on which more sophisticated tests can be
  built.

** Limitations
   The evaluation of the developed artefact is limited several
   ways. As the the study was performed with participants from a
   single country it is difficult to acertain validity across
   cultures.

   Additionally, the sample included only university students and
   socioeconomic factors may therefore bias the range of emotional
   intelligence results obtained in the present study.

   Likewise, the results of the present study are difficult
   to apply to other stimulus sets as differences between stimulus sets
   may affect both the reliability and validity of the overall test.

* Conclusion
  The results of the present study seem to indicate that computerized
  tests for emotional intelligence based on the facial expression
  recognition. Additionally, the present study, shows that combining
  traditional questionnarie-based tests of emotional intelligence with
  more complex ones. Interestingly, the questionnarie-based test used
  in the present study showed poor test-retest reliability. However,
  other tests may be more accurate. Future research could focus
  applying using the developed artefact to differnt questionnaries.

\printbibliography


#  LocalWords:  parencite Mikolajczak citet Schlegel Ekman citep TK
#  LocalWords:  McCleskey Petrides Goleman MSCEIT PEC Brasseur EQ
#  LocalWords:  RaFD dataset fakeability
