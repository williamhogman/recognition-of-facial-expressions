# -*- compile-command: "./compile.sh" -*-
#+begin_src emacs-lisp :results silent :exports none
;; YOU ABSOLUTELY HAVE TO RUN THIS CODE BEFORE DOING ANYTHING
(unless (find "per-file-class" org-latex-classes :key 'car
          :test 'equal)
  (add-to-list 'org-latex-classes
           '("per-file-class"
              "\\documentclass{book}"
              ("\\chapter{%s}" . "\\chapter*{%s}")
              ("\\section{%s}" . "\\section*{%s}")
              ("\\subsection{%s}" . "\\subsection*{%s}")
              ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
              ("\\paragraph{%s}" . "\\paragraph*{%s}")
              ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+end_src
#+BIBLIOGRAPHY: refs plain
#+OPTIONS: num:6 toc:nil title:nil H:6
#+LaTeX_CLASS: per-file-class
#+LaTeX_CLASS_OPTIONS: [12pt,times, twoside, openright]
#+LaTeX_HEADER: \input{preamble.tex}
#+LaTeX_HEADER: \input{meta.tex}

\frontmatterDSV

* Introduction
  Emotions play a fundamental role in modulating the behavior and
  experiences of organisms. While the concept's exact definition is
  debated, its importance is not \citep{Scherer2005}. The impact that
  emotions have on everyday life is enormous, yet hard to pinpoint.

  \citet{Fontaine2007} define emotions as a set of interrelated
  components covering a wide range of behavior. These components are
  appraisals of events, psychophysiological changes, motor
  expressions, action tendencies, subjective experience, and emotion
  regulation \citep{Fontaine2007}. The antecedents of emotions vary as
  do the responses and may be internal as well as external
  \citep{Scherer2005}.

  One important adaptive function of emotions is regulating social
  interactions by facilitating group cohesion and
  collaboration. Understanding the emotions of others is an essential
  aspect of many social situations. \parencite{Niedenthal2012}.

  The literature refers to the ability to process the one's own
  emotional state and that of others as emotional intelligence
  \citep[see~][for~an~early~example]{Salovey1990}. Emotional
  intelligence has, in the last quarter century, gained the attention
  of researchers and has become somewhat controversial. The ability
  encapsulated in emotional intelligence can be conceptualized as
  differences in the extent to which organisms interpret, process, and
  act upon their emotions and affects as well as those of others. An
  essential component of emotional intelligence seems to be the
  ability to identify one's own emotions as well as the emotions of
  others \citep{Mikolajczak2014}. Other cognitive-social abilities can
  be seen as dependent on this base. \citep{Mikolajczak2014}

  The concept of emotional intelligence, however,
  controversial. Various authors with different approaches suggest
  widely different models of emotional intelligence
  \citep[][]{McCleskey2014,Mayer2008,Petrides2010}. Others have
  questioned the validity of emotional intelligence, supporting a more
  limited notion of emotional intelligence. Some studies have found
  emotional intelligence to correlate with personality factors
  \citep[][]{Warwick2004,Petrides2001} and cognitive abilities
  \citep[][]{Freudenthaler2007}. These result call into question
  divergent validity and shed doubt on the concept's overall usefulness.

  Despite the controversy related to the concept, several approaches
  have been used to measure emotional intelligence ability tests
  \citep{Mayer2003}, self-reported ability \citep{Bar-On1997}, and
  personality trait measures \citep{Petrides2007}. For example,
  \citet{Mikolajczak2014} developed a 50-item inventory to measure emotional
  intelligence. \citet{Baron-Cohen2001} approach the problem from a
  different vantage point, asking participants to identify an emotion
  based just on a picture showing a pair of eyes. A different of
  research focuses on measuring emotional facial recognition
  \citep{Schlegel2012}. The results of \citet{Schlegel2012} seem to
  indicate that the recognition of emotional faces is a single ability
  as opposed to multiple separate abilities, affirming to some degree
  the validity of the construct of emotional intelligence.

  Another approach to testing emotional intelligence might be to use
  emotional facial expression classification in a manner similar to
  \citet{Schlegel2012}. The ability to recognize emotions in the faces
  of others seems to be an important social ability
  \citep{Ekman2003}. This suggests that facial expression recognition
  ability could be a measure of general emotional intelligence.

  Facial expressions, \citet{Ekman1969a} find, are largely culturally
  invariant, a prerequisite for valid measure of emotional
  intelligence. \citet{Ekman1992} later defines the set of culturally
  invariant basic emotions later defined as anger, fear, sadness,
  enjoyment, disgust and surprise.

  Cultural invariance is an important property for tests of emotional
  intelligence. Based on the evidence for cultural invariance of
  emotional facial recognitions it seems that facial-expression
  recognition may be an appropriate measure of emotional
  intelligence.

  \citet{Ekman1974a} introduced the Brief Affect Recognition Task
  (BART) as a means to measure emotional recognition. One trial in the
  BART consists of three parts. First, a forward mask showing a
  neutral facial expression. Second, an emotional facial expression is
  displayed. Finally a the first image is displayed again as a
  backward mask.  The first and third images are used to provide
  a fixation and prevent afterimages, respectively. \citep{Ekman1974a}.

** Rationale
   Testing and training applications are central parts of
   microexpression research \citep{Ekman1992}. However, despite
   multiple studies \citep[][]{Schlegel2012},
   there exists no standard for emotional intelligence consisting of
   both emotion recognition and other emotional intelligence models.

   The creation of such a test could be relevant for a number of
   areas. First, education of psychologists, psychotherapists, and
   other mental health professionals might benefit from improved
   training tools; it also could be used to train police and other law
   enforcement professionals. Second, such a test may help
   organizations make better recruiting decisions. Finally,
   development of new tests based on microexpressions, could improve
   the state of the art in psychological testing of emotional intelligence.

** Research Problem
   The lack of a standard test of emotion recognition and emotional
   intelligence, may indicate a lack of understanding about which
   factors are important in developing emotional intelligence tests.

   This thesis sets out sets out to improve the understanding of how
   such testing software could be designed and developed, aiming to
   improve the accuracy and availability of such tests by developing
   such an artifact.

** Research Question
   Could using a software-based multitask test improve emotional
   intelligence test accuracy?

* Extended background
  In the extended background, I review and discuss a number of
  theoretical models, applications, earlier tests and stimulus
  sets. These form the base on which the artifact developed in this
  study was built.
** Theoretical Models of Emotional Intelligence
   The definition of emotional intelligence has, since its inception,
   been the subject of fierce debate \citep{McCleskey2014}. One of the
   key sources of controversy is whether emotional intelligence is an
   ability \citep{Salovey1990}, a competency that one can learn
   \citep{Baron2006}, or a personality trait
   \citep{Petrides2007}. This disagreement may at first seem
   superficial but lies at the core of the issue of measuring,
   understanding, and applying theories of emotional intelligence.

   \citet{Baron2006} primarily advocated the notion of emotional
   intelligence as a competency. His Bar-On model, which he defined
   more precisely as a “cross-section of interrelated emotional and
   social competencies, skills and facilities that determine how
   effectively we understand and express ourselves, understand others
   and relate with them and cope with daily demands.” His model is
   consistent with other frameworks and includes both inter- and
   intrapersonal skills. Like most other models of emotional
   intelligence, the Bar-On models considers a set of widely different
   situations and criteria, ranging from recognizing emotions to
   regulating emotions.

   \cite{Salovey1990} introduced a different notion of emotional
   intelligence, perhaps best defined in the widely cited
   \citep{McCleskey2014} passage, which calls emotional intelligence
   ``the subset of social intelligence that involves the ability to
   monitor one's own and others' feelings and emotions to discriminate
   among them and to use the information to guide one's thinking and
   actions.''

   Additionally, \citet{Salovey1990} divided emotional
   intelligence into four subcategories:
   appraisal, expression, regulation and, utilization, thereby
   defining subject's boundaries.

   Furthermore, \citet{Salovey1990} argue that people possessing the
   four abilities may show more adaptive behaviors in social
   situations. \citet{Brackett2006} confirmed this. Conversely, people
   exhibiting deficits in emotional intelligence may show maladaptive
   behaviors \citep{Brackett2006}.

   Beginning with \citet{Petrides2001}, one strand of research has
   separated emotional intelligence into trait and ability components
   \citep[e.g.,][]{Petrides2007, Petrides2010}. Indeed, a growing body
   of evidence seems to indicate that personality factors explain some
   parts of emotional intelligence
   \citep[e.g.,][]{Warwick2004,Petrides2001}. Specifically,
   \citet{Warwick2004} found correlations between personality factors
   and trait emotional intelligence.

   Building on these results, \citet{Petrides2007}, argues that while
   trait emotional intelligence is a personality trait and
   does not correlate with ability measures of emotional intelligence, it is
   distinct from traditional personality factors.

   \citet{Petrides2010} expands the incompatibility argument further,
   arguing that trait and ability measures of emotional intelligence
   cannot be grouped in any meaningful sense. Moreover,
   \citet{Petrides2010} criticizes the Bar-On \citep{Baron2006} model
   as well as the \citet{Salovey1990} model, arguing that ability
   measures of emotional intelligence imply the existence of some
   universal notion of adaptive social behavior. Such a notion would
   imply a culturally invariant concept of what is socially
   appropriate, or intelligent behaviour, which would be difficult to
   establish.

   To resolve some of the controversies surrounding the term's
   definition, \citet{Cherniss2010} separates the concepts of
   emotional intelligence and social competence and defines emotional
   intelligence simply as recognizing, reasoning, and regulating
   emotions, holding that other factors are simply emotional and
   social competencies, building on emotional intelligence. In effect,
   \citet{Cherniss2010}, designates the \citet{Salovey1990} model as
   emotional intelligence, while referring to the Bar-On model
   \citep{Baron2006} as emotional and social
   competence. \citet{Petrides2010} criticized to reconcile the two
   major theories of emotional intelligence was criticized by
   \citet{Petrides2010} for severing the link between the constructs
   and their present operational definitions. He argues that this
   causes a disconnect between what is actually studied and its
   definition.

   Most authors \citep{Petrides2010,McCleskey2014,DiFabio2014} support
   the separation of trait and state concepts of emotional
   intelligence.  What this separation entails, however, is a matter
   of debate. Proponents of the trait model of emotional intelligence,
   including \citet{Petrides2010}, argue that ability measures of
   emotional intelligence are lacking.  On the other hand, proponents
   of the ability model argue that trait models just measure various
   aspects of personality.

   \citet{Freudenthaler2007} took another approach, interpreting trait
   and ability as typical and maximum performance, respectively; they
   found that typical performance is dependent on personality and that
   maximum performance is dependent on some cognitive ability. This
   model has the advantage of being better aligned with approaches
   taken for other cognitive abilities, not being specific to
   emotional intelligence.

   Having seen multiple definitions of emotional intelligence, what
   little agreement exists can perhaps be stated as \textit{Emotional
   intelligence is a continuous factor determining the depth and
   accuracy of processing at the crossroads of emotion and cognition}.

   Even if earlier integrative approaches have been criticized
   \citep[e.g.,][]{Cherniss2010}, multifaceted approaches may still be
   valuable. Such approaches, however, would require combining
   theoretical frameworks. For any psychometric test to be useful, it
   must be loosely coupled to its theoretical concepts, while
   retaining internal cohesiveness, developing tests; at the
   intersection of theoretical frameworks may therefore make a test
   independent of which framework prevails.

** Practical Applications for Emotional Intelligence

   Despite the difficulty of accurately defining the term, proponents
   of emotional intelligence argue its usefulness.  In a review,
   \citet{Mayer2008} identified seven central results of emotional
   intelligence research, these were:
#+BEGIN_QUOTE
   1. Better social relations for children.
   2. Better social relations for adults.
   3. Better perception by others (highly emotionally intelligent
      individuals are seen more positively).
   4. Better family and intimate relationships.
   5. Better academic achievement (not accounting for IQ).
   6. Better social relations during work performance and in negotiations.
   7. Better psychological wellbeing.
#+END_QUOTE

   Within the areas discussed by \citet{Mayer2008} it seems that
   measures of emotional intelligence have some predictive
   validity. Indeed, the results within the aforementioned areas
   suggest that tests and instruments measuring emotional intelligence
   may be practically applicable.

   Another often-discussed area is the relationship of emotional
   intelligence and leadership. It is commonly held that emotional
   intelligence plays a role in leadership
   \citep{Brackett2006,McCleskey2014}. \citet{McCleskey2014} argues
   that for at least some aspects of leadership, it seems likely that
   emotional intelligence offers some predictive value for performance
   leadership roles. This could make emotional
   intelligence an important tool for executive search.

   Moreover, corporate recruiters have used emotional intelligence
   scales for roles requiring social interaction. This seems to
   suggest that emotional intelligence may be useful in guiding hiring
   decisions \citep{McCleskey2014}.

   Additionally, emotional intelligence testing in diagnosing and
   testing for autism spectrum disorders
   \parencite{Baron-Cohen2001}. The Reading the Mind in the Eyes
   (RTMITE) test of emotion recognition, was developed for this
   purpose \citep{Baron-Cohen2001}.

   Overall, the evidence seems to suggest that the emotional
   intelligence testing is applicable to a number of practical
   situations. This would imply a societal benefit in the application
   of emotional intelligence testing.

** Measuring Emotional intelligence of Ability

   There is also debate about how emotional intelligence is
   measured. There exists, at present, no universally accepted
   standard for measuring emotional intelligence - the different tests
   usually fall into only one of the theoretical models.

   The Mayer-Salovey-Caruso Emotional Intelligence Test (MSCEIT) is an
   early psychometric assessment of emotional intelligence; it is
   based on the theoretical framework introduced by
   \citet{Salovey1990}. Version 2.0 consisted of 141 items across four
   facets of emotional intelligence \citep{Mayer2003}; it measures
   performance based on a set of eight tasks, mapping two tasks for
   each facet. The tasks used in MSCEIT cover a number of different
   emotional abilities including recognition of emotional pictures and
   faces as well as understanding and managing emotions
   \citep{Mayer2003}. One differentiating aspect of MSCEIT is its
   focus on emotional problem-solving, where test-takers face
   imaginary situations requiring emotional intelligence to solve.

   In an evaluation of MSCEIT 2.0, \citet{Mayer2003} found it
   sufficiently reliable as well as consistency with its theoretical
   foundations. This suggests that MSCEIT may be appropriate for
   research use.

    However, \citet{Rossen2008} later disputed MSCEIT's validity,
    finding results running contrary to the structure found the factor
    analysis of the \citet{Mayer2003} validation study. The
    \citet{Rossen2008} results seem to suggest that the subscales do
    not match the intended theoretical concepts, putting the test into
    question.

    For measuring trait emotional intelligence, \citet{Salovey1995}
    introduced the Trait Meta-Mood scale (TTMS), which aims to measure
    the tendency to attend to one's moods and emotions. The TTMS test,
    however, does not correlate with MSCEIT, indicating that it is a
    separate construct from ability \citep{Warwick2004}. The TTMS is
    supposed to capture differences in the tendency to engage in
    socially intelligent behavior, which the ability model does not
    explain \citep{Salovey1995}.

    Self-reported psychometric tests, including the Profile of
    Emotional Competence (PEC), for measuring ability emotional
    intelligence consists of 50 items divided into 10 subscales
    \citep{Brasseur2013}. The PEC shows a good internal consistency,
    making it appropriate for both clinical and research use
    \citep{Brasseur2013}.

    Recently, \citet{Mikolajczak2014} were able to reduce the number
    of items used in the earlier PEC scale to only 20 while, to a
    large degree, maintaining the accuracy of the original 50-item
    scale. This result suggests that a small number of questions can
    be used to measure emotional intelligence.

    Another method of measuring is Emotional Quotient-Inventory
    (EQ-I), a standard questionnaire consisting of 131 items divided
    into five subscales with three facets each \citep{Bar-On1997}. The
    EQ-I is built on the theoretical framework based on emotional
    intelligence as a competency \citep{Baron2006}. EQ-I is often used
    on the individual and peer levels. On the peer level, the
    test-taker's peers are asked to rate the individual's emotional
    intelligence \citep{Bar-On1997}. This approach has recently found
    support in \citet{Elfenbein2015}, showing that such peer ratings
    can be both accurate and reliable.

    The EQ-I is not without its problems, however one is the ability
    to fake, one study conducted by \citet{GrubbIII2007}, found that
    participants were easily able to to fake emotional intelligence
    when asked to do so. This is quite troublesome because it would
    imply that the EQ-I does not measure a competency, because an
    ability would have been difficult to fake.

** Measures Related to Emotional Intelligence

   Some research (outside the development of psychometric tests of
   emotional intelligence) has examined other ways to measure
   constructs related to emotional intelligence and, over time, a
   number of measures relevant to the present study have been
   developed. These tests are developed outside the specific area of
   emotional intelligence, and are to some degree unaffected by the
   controversy surrounding other measures of emotional intelligence.

   One measure that might be considered emotional intelligence testing
   is the Reading the Mind in the Eyes test \citep{Baron-Cohen2001},
   which has been successful in distinguishing people with Asperger
   Syndrome and high-functioning autism from controls. The instrument
   shows good test-retest reliability \citep{Hallerback2009} and has
   been applied in a number of cultures
   \citep{Yildirim2011,Hallerback2009}.

   The Toronto Alexithymia Scale (TAS) is a 20-item test that aims to
   detect alexithymia, the inability to describe one's emotions. The
   TAS consists of two subscales - identifying feelings and describing
   feelings - The measure has shown good validity
   \citep{Bagby1994}. \citet{Bressi1996} found further evidence for
   its showing that good validity could be obtained for Italian
   populations, suggesting at least some degree of cultural
   invariance. Finally, in a functional magnetic resonance imaging
   (fMRI) study, \citet{Berthoz2002} found differences in the
   activation of the anterior cingulate cortex and the mediofrontal
   cortex between people with high TAS-scores and controls. These
   results suggest an underlying neural basis for the TAS score and
   alexithymia, in general.

** Emotional Facial Expressions
   The recognition of emotional facial expressions is a separate but
   related field to traditional emotional intelligence. This strand of
   research builds on the work of \cite{Ekman1969a}. Ekman identifies
   a set of basic emotions that are culturally independent
   \citep{Ekman1987}, occur automatically \citep{Ekman1992,Ekman1997}
   and are automatically processed \cite{Ekman1992}.

   Another feature of Ekman's model is emotional leakage, which occurs
   when one consciously tries to suppress the the expression of an
   emotion \citep{Ekman1969,Ekman2003}. Others can identify emotional
   leakage, which Ekman refers to as microexpressions
   \citep{Ekman1974}.

   Individual and group differences in the ability to detect deceit
   have been found. For example, \citet{Ekman1991}, found that some
   professional groups (e.g., the U.S. Secret Service) are better at
   detecting deceit, using both verbal and non-verbal
   cues. \citet{Frank1997}, seems to suggest that the ability to
   detect deceit is generalized to situations beyond artificial
   testing, lending validity to the concept.

   #+BEGIN_LATEX
   \begin{figure}[htpb]
   \centering
   \label{fig:mett}
   \includegraphics[width=0.5\textwidth]{diamett}
   \caption{One complete trial in the Microexpression training tool (METT) paradigm, consisting of a forward mask, a stimulus and a backward mask. The pictures used in this example are taken from the Karolinska Directed Emotional Faces (KDEF) dataset.}
   \end{figure}
   #+END_LATEX

*** Brief Affection Recognition Test
   Based on this theoretical framework, \cite{Ekman1974a} introduced
   the METT, consisting of very brief displays of emotional facial
   expressions (less than 200ms). Paradigms based on the BART been
   widely used \cite[e.g.][]{Matsumoto2000}. By showing the facial
   expression only for a short time, identification accuracy is
   reduced compared to longer exposure times. Ensuring that the
   chance-adjusted hit rate is as close to 50% as possible is
   important for avoiding floor and ceiling effects which could
   distort the data. One of METT's important features is masking
   images of neutral faces before and after a trial
   \citep{Ekman1974a}. Masking images provide a fixation point before
   the trial and ensures that the participants do not have the
   benefit of after-images. This paradigm is illustrated in
   \ref{fig:mett}

*** Subtle Expression Training Tool
    The Subtle Expression Training tool (SETT) is another method of
    ensuring low accuracy is the. Unlike the METT, expressions are
    restricted to one part of the face. This is meant to simulate a
    situation where the person is consciously suppressing a facial
    expression. \citep{Ekman2003}

** Stimulus Sets of Emotional facial expressions

   To use the methodologies discussed, it is necessary to use a set of
   photographs. Because facial expressions recognition is a common
   task, a plethora of facial expression stimulus sets have been created.

   These stimulus sets are suitable for many kinds of research. For
   the present study, I reviewed a number of number of stimulus sets
   and the research surrounding them. The stimulus sets I reviewed do
   not represent a complete coverage of all stimulus sets created, but
   I aspired to sufficient coverage of stimulus sets in common use.

   The Japanese and Caucasian Facial Expressions of Emotion (JACFEE)
   \citep{matsumoto1988japanese} was an early stimulus set, consisting
   of 56 photos of models of Japanese or Caucasian descent with eight
   pictures, one for each basic emotion and one neutral picture. The
   dataset, while showing some cross-national differences also showed
   relatively high levels of agreement \citep{Biehl1997}.

   The Karolinska Directed Emotional Faces (KDEF) is another commonly
   used stimulus set of emotional facial expression
   \citep{DanielLundqvistAndersFlykt1998}. It consists of 70 pictures
   of individuals expressing seven different emotions from five
   angles. KDEF has, since its inception, seen much use in facial
   expression research
   \citep[e.g.][]{Calvo2008a,Willis2006,Todorov2009}. In addition to
   its widespread use, KDEF has shown good test-retest validity and a
   high degrees of accuracy in recognition tasks \citep{Goeleven2008},
   indicating that the stimulus set is appropriate for research use.

   \citet{Beaupre2000} approached the issue of finding a good stimulus
   set from the perspective of cultural differences in the ability to
   recognize emotions. The Montreal Set of Facial Displays of Emotion
   (MSFDE) \citep{Beaupre2000} consists of facial expressions where
   the actors were instructed to pose facial expressions based on
   Ekmans' model. The full stimulus set consists of 144 images, with
   six types of facial expressions and three ethnic groups: French
   Canadians, Chinese, and sub-Saharan Africans.  \citet{Beaupre2005}
   validated the MSFDE and it exhibited a large degree of cultural
   invariance.

   NimStim \citep{Tottenham2009} is another set, consisting of 672
   images of 43 professional actors instructed to pose eight different
   emotions with both open and closed-mouthed expressions. In their
   evaluation \citet{Tottenham2009}, found that the set's reliability
   was good. They also selected a recommended subset of the images for
   which reliability is good; for use in future studies.

   RaFD, the Radboud Faces Database \citep{Langner2010}, is a more
   more recent contribution. It contains photographs of 49 models
   expressing eight emotions with three gaze directions, taken from
   five camera angles for a total 5880 photographs. Upon validation,
   RaFD showed a very high accuracy, higher than the earlier KDEF
   data set \citep{Langner2010}. A key difference between RaFD and
   KDEF, which perhaps explains the difference in accuracy, is the
   expression coaching RaFD models received from a facial expression
   coding expert \citep{Langner2010}.

   \citet{Calvo2008a} investigated the relationship between the
   presentation time (25-500ms) and the accuracy of emotion
   recognition in a nonmasked emotion recognition task, with the KDEF
   stimulus set, and found a slight increase in accuracy for longer
   displays. In addition, \citet{Calvo2008a} found differences in
   detection between the emotions. Happy and neutral showed higher
   degrees of accuracy than the other emotions, and fear showed lower
   accuracy.

   Those results suggest that there are differences in the accuracy of
   processing different emotions. Most importantly, it seems that
   accuracy rates for facial expressions of happiness and neutral
   expressions are much higher than those of other expressions
   \citep{Calvo2008a}. We must, therefore, take care to avoid ceiling
   effects in general and happiness in particular.

   Another strand of research has looked into the split-second trait
   judgments made when viewing a face. \citet{Willis2006}, found very
   strong correlations between judgments of trustworthiness made after
   \SI{100}{\milli\second} or \SI{500}{\milli\second} versus those
   made without time constraints. Moreover, no significant difference
   was found between the \SI{100}{\milli\second} and
   \SI{500}{\milli\second} conditions, suggesting that a trait
   judgment is performed very quickly. \citet{Todorov2009} further
   expanded this notion finding that accuracy grew with display times
   up to \SI{100}{\milli\second}, after which the growth rate is
   dramatically slower. These results are important, as they seem to
   indicate the depth of facial processing that occurs even at low
   presentation times.

   One problem all the stimulus sets discussed here share is that they
   consist only of still images. One could argue that the dynamics of
   facial expressions play an important role in recognizing
   emotions. Indeed, emotional facial expressions play out in nature
   this way. This problem has led to the development of a number of
   video-based stimulus-sets for facial expression. The GEMEP, Geneva
   Multimodal Emotion Portrayals, \citep{Banziger2012} is one of
   these. The GEMEP contains audio and video for each expression,
   providing three options for stimulus displays, audio-only,
   video-only and, audio-video. The GEMEP stimulus-set is extensive,
   with 1260 expressions, spread out over 18 emotions,
   10 actors, three angles, and a varying number of repetitions and
   verbal content \citep{Banziger2012}.

   Based on the research discussed in this review, it could be argued
   that measuring the recognition facial expressions may be successful
   in finding individual differences in emotional processing. This
   difference seems particularly pronounced at presentation times
   shorter than 1 second.

* Methodology and Methods for Data Collection
  This study's goal is not merely empirical; it aims also
   to design a computerized test of emotional intelligence. The
   distinction between design science and normal research is discussed
   further by \citet[chapter~1]{Johannesson2014}, who hold that
   practical problems ought to be addressed with design research
   approaches.

   \citet[chapter 4]{Johannesson2014} put forward a model of design
   science based on five activities: \textit{Explicate
   Problem} aims to find the practical problems that need solving. The
   second activity, Define Requirements, finds which requirements
   should be developed. The third, Design and Develop artifact
   concerns the creation of the artifact. The fourth stage,
   Demonstrate Artifact aims to demonstrate that the artifact solves
   the actual problem. Fifth, Evaluate artifact, which shows the
   extent to which the artifact solves the intended problem.

   By using these stages, \citet{Johannesson2014} argue that the
   successful application of design science, helps researchers, choose
   what to develop, and how to develop and evaluate it.

   \citet{Hevner2007} has another approach to design science,
   consisting of three cycles: \textit{Relevance}, where the subject
   area an its requirements are identified; \textit{Design} where the
   artifact is designed and deployed; \textit{Rigor} where the
   researcher applies and grounds the developed artifact in existing
   theories, perhaps resulting in meta-artifacts, suitable for
   research or practical use.

   The paradigm presented by \citet{Hevner2007} is different in many
   aspects from that of \citet{Johannesson2014}. Whereas
   \citet{Johannesson2014} emphasize a larger set of well-defined
   activities, \citet{Hevner2007} put forward a less structured set of
   cycles to be performed iteratively.

   The design science method introduced by \citet{Peffers2008} differs
   from the methods of \citet{Johannesson2014} and \citet{Hevner2007}.
   Design science, in their paradigm has six stages, conducted
   iteratively. The stages they describe are:

   - Identify Problem and Motivate
   - Define Solution Objectives
   - Design and Development
   - Demonstrate
   - Evaluate
   - Communicate
   The model allows any stage of the design process as an entry point the
   for research process, making it fit better with actual
   practice.

   While the methodology of both \citet{Hevner2007} and
   \citet{Peffers2008} shows promise, the stages
   \citet{Johannesson2014} present better fit the present study,
   because it has a defined starting point, and activities are similar
   to the stages of the normal software development lifecycle.

** Chosen Stages
   Because of this study's limited scope, I performed only a subset of
   design science activities. The stages selected were chosen to
   ensure that a viable, meaningful artifact could be developed
   developed.  I selected the following stages, because they were the
   fastest way to reach an actual artifact given scope limitations:
   - Requirements definition
   - Implementation
   - Evaluation

** Choice of Method
   For each chosen stage of the design science process, different
   methodological considerations were made. These are discussed
   separately below. For the purposes this study, I consider a number
   of possible approaches.

*** Requirements Definition
    An extensive number of research methods can be used for
    requirements definition. Many popular approaches involve potential
    stakeholders directly. Surveys are often used for this purpose,
    and allow researchers to directly ask stakeholders about their
    requirements \citep[chapter 6]{Johannesson2014}.

    Using surveys runs the risk of not being able to find innovative
    requirements because the stakeholders themselves are sometimes
    unable to identify any requirements sufficently dissimilar from
    the present solution.  \citet[chapter~6]{Johannesson2014} suggest
    using other methods, such as case studies and action research, to
    find requirements that the stakeholders were unable to
    identify. These methods, however, have the drawback of applying the
    researchers' personal views to the requirements
    \citep[chapter~6]{Johannesson2014}.

    This present study's domain is complex. Test-takers are
    unlikely to understand the intricate nature of the subject area,
    and their interests do not align with the people administering the
    test. Similarly, practitioners do not always possess a sufficient
    understanding of the tests.

    Finally, it is difficult to find a significantly large population
    of researchers to establish qualitative saturation. This would in
    the view of \citet[chapter~6]{Johannesson2014}, restrict the
    studies to documents.

    It could be argued that using documents only is sub-optimal for
    many cases. In present study, however, the situation is for very
    different.

    To capture the requirements for the present study successfully, I chose
    two methods:
   - A literature review of emotional intelligence and methods of
     testing it and
   - A quantitative analysis of existing data collected from earlier
     applications of a microexpression test.

   I selected these methods to capture variance from the scientific
   literature as well as empirical data. Combining different methods
   may allow for better capture of the relevant aspects of emotional
   intelligence and sufficient coverage of the domain.

   I chose literature to ensure a sufficient degree of
   qualitative coverage of the research area. Wide qualitative
   coverage is particularly important because of the controversial
   nature of the emotional intelligence. Wide coverage
   allows for finding a agreed-upon definition of emotional
   intelligence, which is necessary for the developed artifact to be
   useful.

   The quantitative analysis of earlier data constitutes experimental
   method \citep{Denscombe2010}, because the data was collected in an
   experimental setting. The existence of prior data motivates the
   choice of quantitative analysis of data gathered by experimental
   methods; because this data is already collected, using it has very
   low costs. Analysis of such data would allow for empirical answers
   to questions that may be relevant for the study.

   By combining an exploratory literature study, giving insights into
   many areas of emotional intelligence, with an empirical analysis of
   earlier data, the present study can define requirements based on
   precise facts about the domain, as well insights spread out across
   the literature. This combined strategy is likely to give the domain
   broad and deep coverage.
*** Implementation
    A large number of processes have been devised for the
    implementation of software artifacts. Early research largely
    focused on very formalized processes, and less formal methods of
    software development were largely ignored. In practice, these
    processes were often misaligned. A number of of agile software
    development process have appeared, counteracting this misalignment.
    \citep{Abrahamsson2002}. Better alignment between practice and
    process may yield better results.

    \citet{Abrahamsson2002} discuss a number of methods. The most
    prominent are perhaps Extreme Programming, (XP), Crystal, Rational
    Unified Process (RUP), and Scrum. These methods recommend
    implementing suggested processes only if they are useful to the
    project \citep{Abrahamsson2002}.

    With the turn of the millennium, research attention started to
    shift toward agile processes. These processes have become commonly
    in both academic projects and in the industry
    \citep{Abrahamsson2002}.

    With the research consensus that processes should be enacted
    on an as-needed basis, it seems reasonable for a project with
    little need for formal process to use very little formal process.

    To implement the artifact, I used unstructured iterative
    development process. The process choice was made because the
    project's scope was small. The development process continued until
    the developed artifact fulfilled the identified requirements.

*** Evaluation
    I performed the evaluation of the developed artifact was performed
    using experimental methods. Experimental methods are often used to
    evaluate psychometric instruments. Because experimental methods
    are common this makes them a good fit for the present
    study. Generalization is the developed psychometric test's goal,
    by controlling irrelevant factors to the greatest extent possible
    researchers are better able to establish generalizability. This
    could, of course, reduce the ecological validity of the
    instrument. The reduction of ecological validity is a problem
    shared by many psychometric instruments, and therefore not a
    problem particular to this study.

* Application of Method
** Requirements Definition
   For the literature review, I reviewed a number of research
   publications related to emotional intelligence. Based on these, I
   performed qualitative coding based analysis. Different psychometric
   measures of emotional intelligence were coded based on theoretical
   models, scales and subscales.

   I coded stimulus sets in a similar fashion, taking into account the
   number of models participating, the emotions expressed, and the
   ethnicities.

   For the quantitative data analysis, I used a data from number of
   studies (Table \ref{listofstudies}) and analyzed each data set
   separately. All the studies whose data was analyzed used the METT
   methodology, and followed similar protocols, thereby making them
   essentially comparable.

   For the first study, I computed overall hit-rates and
   descriptives. After computing overall statistics, I created a
   confusion matrix and computed a set of variables related to the
   signal detection theory. These variables are all derivable by using
   four variables: $H$, the number of hits (true positives); $CR$, the
   correct rejections (true negatives); false alarms $FA$ (false
   positives); and misses $M$ (false negatives).

   \begin{equation} \label{e_hr}
   \mathit{HR} = \frac{H}{H + M}
   \end{equation}

   Equation \ref{e_hr} defines the hit rate, also called the
   true-postive rate or recall.

   \begin{equation} \label{e_crr}
   \mathit{CRR} = \frac{CR}{CR + FA}
   \end{equation}

   Equation \ref{e_crr} defines the correct rejection rate, sometimes
   referred to as specificity.

   \begin{equation} \label{e_ppv}
   \mathit{PPV} = \frac{H}{H + FA}
   \end{equation}

   Equation \ref{e_ppv} defines the positive predictive value.

   \begin{equation} \label{e_npv}
   \mathit{NPV} = \frac{CR}{CR + M}
   \end{equation}
   Equation \ref{e_npv} defines the negative predictive value.

   \begin{equation} \label{e_balanced_accuracy}
   \mathit{BalancedAccuracy} = \frac{HR + CRR}{2}
   \end{equation}

   Equation \ref{e_balanced_accuracy} defines the balanced accuracy.

   For the second study, I extracted per-trial data, for the
   psychotherapist group. A cross tabulation of hits and misses for
   each trial was constructed such that the number of hits and misses
   by trial number could be investigated. I then entered this data
   into a linear model.

   Finally, the results of the literature review and the quantitative
   analysis of earlier data were integrated to create requirements for
   for the artifact.

\input{summaryearlier.tex}

** Implementation
   The software artifact designed for the study was developed
   incrementally in iterations, aiming to fulfill a growing subset of
   the requirements. No single development process was selected;
   instead, a number of practices were selected to guide the
   development process.

   This sort of exploratory process allows developers to better adapt
   the software they're creating as their understanding of the
   requirements grows.

   Automated unittests were developed in an ad-hoc manner as part of
   the overall development process and were aimed primarily as an
   development aid.

   An application using the PsychoPy library \citep{Peirce2007} was
   developed. PsychoPy is a module designed for the Python 2
   programming language, aimed at providing functionality for building
   psychological experiments. I used the PsychoPy library, because it
   offers excellent accuracy in the presentation of
   stimuli. Additionally, PsychoPy has excellent data collection
   components, allowing for greater ease of data processing.

** Evaluation

*** Participants
   The participants ($n=81$), all university students, took part in the
   experiment as part of a course requirement. Thirty-one of these
   participants took the test twice.

*** Apparatus
    The software under evaluation was executed on a laptop PC running
    the Windows 7 operating system. The software ran under the
    PsychoPy 1.82 environment. No noticeable performance issues were
    identified.

*** Procedure
    Participants were positioned approximately 70 cm from the
    screen. The designed software artifact was run. The test software
    was configured to run a set of 70 trials, and the question module
    configured was to gather responses. After completing the
    experiment, the group taking the test twice was scheduled for
    another test session.

*** Data analysis
    I analysed the data using both the R programming langauge
    \citep{R2015} and statistical environment, as well as a
    Python-based environment using SciPy \citep{SciPy} for statistical
    analysis, iPython \citep{IPython} for reproducible analysis, and
    Pandas \citep{mckinney-proc-scipy-2010} for data management.

**** METT-related analysis
     After reading data from the disk and combining it, I computed
     hit-rates and descriptive statistics, as well as the number of
     participants completing the test without misses for a certain
     emotion. Kernel density estimates were used to visualize the
     distributions.

     For the 31 participants who took the test twice, test-retest
     reliability was computed, using Pearson's $r$. The fraction and
     number of participants who correctly identified each stimulus was
     computed. Kernel density estimates per emotion were also created.

     In order to analyze effects to training, happening, I constructed
     a linear model with the trial number as the predictor.

**** SPEC-related analysis
     First, inversions of items and subscales were computed, and then
     descriptive statistics were computed for the overall scale as
     well as the subscales. Correlations between each subscale were
     computed, and finally, correlations between the METT and the SPEC
     results were computed.

** Ethics
   Participation in the study was entirely voluntary; participants
   were informed about this fact and signed informed consent forms
   before participating. I collected no identifying information during
   the course of the study. I could identify no ethical concerns
   particular to this study, and the conduct of the study followed
   standard research practices. Additionally, as the study was
   performed pursuant to a master’s degree, it was not required to be,
   nor was it, submitted for external ethical review.

* Results
** Requirements Definition
*** Literature review
    From reviewing the literature, I found a number of methods for
    measuring emotional intelligence; these are presented in table
    \ref{table:paradigms}. The methods discussed earlier cover many
    aspects of emotional intelligence more than can realistically be
    used for single experimental study. Therefore subset of these will
    be selected for the evaluation.

    \input{paradigms.tex}

    In addition to general test paradigms, I considered the stimulus
    sets from the reviewed literature. I present these in table
    \ref{table:stimsets}.

    \input{stimsets}

*** Analysis of old data
    I analysed each of the data sets used in the study separately,
    with the goal of identifying data characteristics, which I then
    used to identify possible requirements for the system.

    The first data set consists of 2149 correct responses and 1351
    incorrect responses for a total of hit rate of 61%. I computed
    confusion as shown in Table \ref{study1confusion}. In Table
    \ref{study1classtable}, I show characteristics for each
    emotion. Expressions of disgust have by far the lowest balanced
    accuracy; participants were unlikely to answer disgust. Anger was
    the most accurately detected emotion.

    \input{study-one-hitrates-emotion.tex}

    The second data set consisted of 72 participants, where the
    average accuracy was $72.99\%$ ($S=12.14$).

    #+CAPTION: Hit rates and standard deviations by emotion in study 2.
    #+ATTR_LATEX: :environment tabulary :align lll :width \textwidth
    | Emotions  |  $HR$ |   $S$ |
    |-----------+-------+-------|
    | Disgust   |    64 | 25.98 |
    | Happiness | 90.05 | 18.98 |
    | Surprise  | 90.85 | 14.37 |
    | Anger     | 79.15 | 20.87 |
    | Contempt  | 57.25 | 33.88 |
    | Fear      | 68.75 | 23.75 |
    | Sadness   |  60.9 | 26.26 |

    To investigate the effects of training, I constructed a linear
    model with the number of trials as the independent variable and
    hit rate as the dependent variable. A significant effect of
    trial number was found ($t=4.56$, $p<0.001$, $df=68$). This effect
    indicates that accuracy improves throughout the experiment.

*** Requirements
    In this section, I discuss and develop a set of requirements based
    on the earlier data and literature review.

**** Choice of Tests
    In reviewing earlier research, I found a number of suitable tests
    for emotional intelligence. However, many of the standard measures
    of emotional intelligence are highly controversial. Of these, the
    METT is perhaps the least controversial. Falling outside the
    traditional distinction between trait and state emotional
    intelligence, the METT avoids some of this controversy by focusing
    only on the recognition of microexpressions. Based on the earlier
    data, METT seems to many beneficial characteristics for such a
    test.

    It is, however, unlikely that emotion recognition tasks can
    capture every aspect of emotional intelligence; using other
    methods may capture other sources of variance. On the other hand,
    using too many inventories may lead to a measure that takes too
    long to complete - reducing measure's reliability and increasing
    time-related costs. Therefore, it is important to keep any such
    tests as short as possible.

    MSCEIT, EQ-I, and PEC contain a large number of items, which is
    acceptable for standalone use; however, using them in conjunction
    with other tests may be unsuitable, it is overly
    time-consuming. This leaves TAS, RTMITE, and SPEC as suitable
    candidates. Being a facial expression recognition task, RTMITE, is
    very similar to the METT, and for this reason it is unsuitable for
    capturing complementary sources of variance.

    TAS, while showing robustness, maturity, and validity, is limited
    in that it only includes sub-factors related to alexithymia, and
    may for this reason be more appropriate for assessing
    dysfunctions. Moreover, one of the factors, identifying feelings
    may overlaps METT. This makes it unsuitable as a supplementary
    test to METT.

    Considering the aim of capturing qualitatively different factors
    from METT, SPEC may be the most appropriate test. SPEC provides a
    the same number of factors as the longer PEC while retaining much
    of the reliability. Given the need for wide coverage of emotional
    intelligence-related factors, as well as the time-constraints,
    SPEC seems to be the most suitable test.

    Having considered all the tests discussed in the literature
    review, I chose two, METT and SPEC. The test implemented a
    facial-expression task and a digital questionnaire, configured for
    METT and SPEC respectively.

**** Timing
    As discussed earlier \citep[recall][]{Calvo2008a}, even a small
    difference in the duration in the display time of a METT trial has
    a great effect on accuracy, particularly at low exposures. It is
    therefore important that exposure times be controlled to a
    reasonable degree. To ensure this, display times must be specified
    in numbers of frames. This aligns the intended display times with
    the monitor's refresh rate, thereby ensuring some degree of
    accuracy.

    While there are clear differences in accuracy between different
    emotions, no consideration given to the emotional types when
    deciding on presentation times, because doing so would render the
    different emotions incomparable, which would limit the insights
    that can be gained from the test.

    Because the experiment process is time-consuming for both the
    participant and the experimenter, crashes in software running the
    experiments is wasted time and can frustrate everyone. It is,
    therefore, important to ensure that the system is stable and avoids
    data loss to as large an extent possible, given available development
    resources and the study’s scope.

**** Input
    Additionally, a means of input must be selected. For the purposes
    of the present study, a standard keyboard is the most suitable
    input device for the test being developed, for several
    reasons. First, it allows faster responses once the user has
    learned the options. Second, not showing a mouse-cursor avoids
    problems stemming from the occlusion of the stimulus by the mouse
    cursor. Finally, keyboards are commodity hardware and using them
    removes the need to buy specialized input hardware, making the
    test accessible to a wider range of researchers and practitioners.

**** Training effects
    Another issue is training effects. As the results from the
    analysis of earlier data showed, there was a strong training
    effect ($p<0.001$). Specifically, the earlier data showed a clear
    linear training trend of increasing accuracy throughout the
    experiment. In the data sets considered in the present study no
    clear ending was found to this trend. The lack of an end, even
    after 70 trials, suggests that training effects are still relevant
    after a substantial number of trials. For this reason, to ensure
    that data gathered using the test is comparable between
    individuals, the number of trials needs to be the same for all
    individuals.

**** Stimulus sets
    Finally, the issue of stimulus set needs to be addressed. In the
    data from the earlier studies I found that performance was in line
    with what is typical for the METT paradigm; it is therefore
    reasonable to assume that there are no additional issues with the
    RaFD data set used in these. It seems appropriate to use RaFD for
    evaluating the artifact developed for this study, while leaving
    the data set as a configurable variable.

**** Requirements Specification
    Using the conclusions drawn above, I derived a number of requirements:

    1. Requirements pertaining to the METT test:
       1. Functional: The system shall display a forward-mask.
       2. Functional: The system shall display a backward-mask.
       3. Functional: The system shall display a target-image.
       4. Functional: The system shall ensure that presentation times are precise within  \SI{1/60}{\second}.
       5. Functional: The system shall collect input indicating the selected emotion via the keyboard.
       6. Functional: The system shall perform the same number of trials for each participant.
       7. Functional: The system shall allow configuration of stimulus sets.
    2. Requirements pertaining to the SPEC test:
       1. Functional: The system shall show the questions.
       2. Functional: The system shall collect numeric responses via keyboard input.
    3. Requirements pertaining to data collection, endurance and persistence:
       1. Functional: The system shall store results to disk in the Comma Separated Values (CSV) format.
       2. Nonfunctional: The system shall be stable to avoid data loss.
    4. Requirements pertaining to ease of use
       1. Nonfunctional: The system shall be simple to initialize.




** Implementation
   #+INCLUDE: "result_implementation.org"

** Evaluation
   The analysis of the data gathered in the study can be divided into
   METT and SPEC data. In the following sections, results related to
   the both will be presented.
*** Microexpression Testing Tool
    A total of $4268$ responses were collected, of which $2977$ were
    correct and $1291$ were incorrect, for an overall hit rate of
    $69.1887\%$. Hit rates divided by emotion are presented in Table
    \ref{table:metthitrate}.

    #+LATEX: \input{metthitrate}

    The number of participants correctly identifying every stimulus of
    each emotion correctly are presented in Table
    \ref{table:mettnomiss}.

    #+LATEX: \input{mettnomiss}

    Kernel density estimates were computed for each emotion
    separately; these are presented in Figure \ref{fig:kde}. Happiness
    and surprise, assuming a normal distribution, have seen large
    restrictions of range.

    #+BEGIN_LATEX
    \begin{figure}[htpb]
    \centering
    \label{fig:kde}
    \includegraphics[width=1\textwidth]{result-analysis/kde}
    \caption[Hit rate Kernel Density Estimates per Emotion]{Kernel Density Estimates of Hit rates for each emotion}
    \end{figure}
    #+END_LATEX

    For the 31 participants taking the test twice, the measured
    test-retest correlation of $r=0.8542$ ($p < 0.001$, $df=29$).
    This level of reliability is considered good ($0.7 \leq r < 0.9$).

    Table \ref{table:metttestretest} presents test-retest correlations
    for each emotion individually. This level may however, be deflated
    by a limitation of range for some emotions. Indeed, happiness
    which causes ceiling effects, shows a low,
    correlation. Additionally, surprise and fear show lower
    correlations compared to the other emotions.  Contempt and
    disgust, on the other hand, show higher correlations than the
    other emotions.

    The low correlation for fear is somewhat surprising, given the
    fact that there is no obvious restriction of range discernable
    from visual inspection of the kernel density estimates.

    #+LATEX: \input{testretest}
*** Short Profile of Emotional Competence
    Table \ref{table:specdesc} presents the descriptive statistics for
    the SPEC subscales.
    #+LATEX: \input{specdesc}

    A correlation matrix was for the SPEC subscales is presented in
    Table \ref{table:speccorrmtx}. Table \ref{table:specmettcorr}
    presents correlations between the SPEC subscales and the METT
    results.

    #+LATEX: \input{speccorrmtx}

    The test-retest correlation for the SPEC was $r=0.5070$ ($p <
    0.01$, $df = 29$). A test-retest correlation of $r < 0.6$ is
    considered poor. Test-retest correlations of the individual
    subscales are presented in table \ref{table:specmettcorr}.

* Discussion
  The main finding was that the developed METT test showed good
  reliability.  Test-retest scores correlations indicated good
  test-retest reliaiblity, also the split-half reliability was
  good. SPEC and METT were uncorrelated, suggesting that SPEC and METT
  measure different qualities, indicating that combining different
  tasks may improve the coverage of the test. Additionally low
  reliability for SPEC was found.

** METT

  The test however, did not avoid the common ceiling effects for
  happiness. A majority of participants ($72.83\%$) correctly
  identified every single happy emotional face in the METT part of the
  experiment. Indeed, as seen in the kernel density estimates
  presented in figure \ref{fig:kde}, a large portion of the
  distribution for happiness was cut-off. This is indicative cieling
  effects.

  The higher accuracies for expressions of happiness found in the
  present study have also been found in earlier studies; recall
  \citet{Calvo2008a}, the present study confirms these earlier
  results.

  In future iterations, limitations of range of the kind found in the
  present study should be avoided. The results seem to suggest that if
  ceiling effects for happiness could have been avoided, the test
  would have had higher reliability. This could make it more suitable
  for high-stakes testing, which is usually reserved for tests showing
  reliabilities above $0.85\%$. Interestingly, our results seem to
  suggest that surprise is affected be ceiling effects, limiting which
  may also increase reliability.

  One method for reducing accuracy is simply reducing the time
  presentation time. However, some expressions, such as fear, where
  the average hit rate is lower, may cause floor effects
  instead. Using different presentation times for different emotions,
  could solve this. While using different presentation times might
  improve the overall quality, it would make the emotions
  incomparable.

  A possible focus for future research could be to investigate methods
  for minimizing the effects and occurence of range limitation. A
  number of methods could be implemented to avoid these.

  One possible solution would be to have varying display times within
  each emotion, such that the test would include a number of different
  conditions with different presentation times. Such an approach
  would, if calibrated properly, avoid both floor and ceiling
  effects. Using an adaptive testing procedure such as this could
  improve the test, but is not entirely without related development
  costs.

  Other possible solutions, such as staircase and threshold methods,
  could also be used. In such methods, the minimal presentation time
  to achieve a certain level of accuracy for a given individual is
  established.

  Changing the stimulus set to be more challenging could be another
  option. Most stimulus-sets (e.g. KDEF, \citet{Langner2010}; MSFDE,
  \citet{Beaupre2000}), including the one used in the present study
  are designed to be easily recognizable. It seems likely that using a
  stimulus set where expressions of happiness and surprise are less
  overt could lead to a decrease in ceiling effects.

** SPEC
  Another finding was the relatively low correlations between the
  subscales of the SPEC. This conforms to the earlier results of
  \citet{Brasseur2013} and lends divergent validity of the structure
  of the SPEC and PEC.

  However, the test-retest reliabilty found in this study for SPEC was
  poor, calling into question its value. One possible cause for lower
  test-retest reliability might be the translation used in the present
  study. While there were some differences between the subscales, it
  is clear that none of the scales reached good
  reliability. Translation differences are unlikely to cause such poor
  test-retest reliability as the same translation is used twice ---
  poor test-retest reliabilty could be indicative of a of number
  factors unrelated to the translations the actual test. It may be the
  case that the trait measured in the SPEC is not stable, and instead
  varies with mood. Improvements to the method presented in this
  thesis could be made using another instrument.

** Combining SPEC  and METT

  The results of the present study, showing low correlations between
  the SPEC and METT, seem to indicate that the scales, measure
  different facets of emotional intelligence. Indeed, as discussed in
  the literature review, SPEC and METT belong to different theoretical
  frameworks of emotional intelligence. It seems that the SPEC,
  measuring a trait, gives very different results compared to the
  ability-based METT.

  Exactly trait scales of emotional intelligence measure is debated,
  at; the very least, it gives an indication of an individual's
  appraisal of his or her own emotional intelligence.  On the other
  hand, the poor test-retest correlations found might indicate that a
  different test of trait emotional intelligence should have been
  used. Indeed, future research could apply a number of different
  scales, attempting to find with higher reliability. The artifact
  developed in the present study allows for question-sets to be
  specified in configuration, thereby making it easy to apply it to
  different tests.

** Limitations
   The evaluation of the developed artifact is limited in several
   ways. As the the study was performed with participants from a
   single country it is difficult to ascertain validity across
   cultures.

   The sample included only university students, and
   socioeconomic factors may therefore bias the range of emotional
   intelligence results obtained.

   Likewise, the results of the present study are difficult
   to apply to other stimulus sets, as differences between stimulus sets
   may affect both the reliability and validity of the overall test.

** Ethics and Implications
   Testing emotional intelligence has many societal and ethical
   implications. In many regards the ethics and implications of
   emotional intelligence are similar to those of traditional
   intelligence, and perhaps to all psychometrics.

   At the same time, claiming any great implications of small study
   such as this one, is at best intellectually dishonest. This study
   represents only a small increment added to larger
   whole. Speculating on the grander effects of this field, even after
   thorough study, is so imprecise so as to be best left to the
   reader.

** Conclusion
  The test developed in the present study has both practical and
  academic uses. The artifact is adaptable to a number of test
  methodologies and can be used for both psychological research and
  practical emotional intelligence testing. It also provides a
  foundation on which more-sophisticated tests can be built, in what
  could perhaps be a fruitful avenue for future research.

  Despite the limitations related to expressions of happiness and
  surprise, the artifact developed in the present study offers some
  good properties. The test, being mostly ability-based, is robust to
  faking and social desirability. It captures both personality traits
  related to emotional intelligence as well as the actual ability to
  read emotional cues in the facial expressions of others.

  The study's results seem to indicate that computerized
  testing is a worthwhile field and while the re-retest reliability
  of the survey portion leave room for improvement, such improvement
  is left for future researchers.

\printbibliography
\finalpageDSV

#  LocalWords:  parencite Mikolajczak citet Schlegel Ekman citep TK
#  LocalWords:  McCleskey Petrides Goleman MSCEIT PEC Brasseur EQ
#  LocalWords:  RaFD data set fakeability
